api,template
NodeClustering,"To handle the issue,
we can leverage NodeClustering class.

The NodeClustering class is beneficial for Node Communities representation.
The NodeClustering class takes these parameters:
""""""
communities: list of communities\n graph: a networkx/igraph object\n method_name: community discovery algorithm name\n method_parameters: configuration for the community discovery algorithm used\n overlap: boolean, whether the partition is overlapping or not
""""""

The class's path can be found at cdlib.NodeClustering.


"
NodeClustering.adjusted_mutual_information,"To address the problem at hand,
we can utilize NodeClustering.adjusted_mutual_information method.

The NodeClustering.adjusted_mutual_information method is designed to Adjusted Mutual Information between two clusterings. Adjusted Mutual Information (AMI) is an adjustment of the Mutual Information (MI) score to account for chance. It accounts for the fact that the MI is generally higher for two clusterings with a larger number of clusters, regardless of whether there is actually more information shared. For two clusterings \(U\) and \(V\), the AMI is given as: AMI(U, V) = [MI(U, V) - E(MI(U, V))] / [max(H(U), H(V)) - E(MI(U, V))]  This metric is independent of the absolute values of the labels: a permutation of the class or cluster label values won’t change the score value in any way. This metric is furthermore symmetric: switching label_true with label_pred will return the same score value. This can be useful to measure the agreement of two independent label assignments strategies on the same dataset when the real ground truth is not known. Be mindful that this function is an order of magnitude slower than other metrics, such as the Adjusted Rand Index. .
The NodeClustering.adjusted_mutual_information method returns:
""""""
AMI score
""""""

The method's path is located at cdlib.NodeClustering.


"
NodeClustering.adjusted_rand_index,"To resolve this issue,
we can use NodeClustering.adjusted_rand_index method.

The NodeClustering.adjusted_rand_index method serves to Rand index adjusted for chance. The Rand Index computes a similarity measure between two clusterings by considering all pairs of samples and counting pairs that are assigned in the same or different clusters in the predicted and true clusterings. The raw RI score is then “adjusted for chance” into the ARI score using the following scheme: ARI = (RI - Expected_RI) / (max(RI) - Expected_RI)  The adjusted Rand index is thus ensured to have a value close to 0.0 for random labeling independently of the number of clusters and samples and exactly 1.0 when the clusterings are identical (up to a permutation). ARI is a symmetric measure: adjusted_rand_index(a, b) == adjusted_rand_index(b, a)  .
The NodeClustering.adjusted_rand_index method provides:
""""""
ARI score
""""""

The method's path is located at cdlib.NodeClustering.


"
NodeClustering.average_internal_degree,"To solve this problem,
we can utilize NodeClustering.average_internal_degree method.

The NodeClustering.average_internal_degree method is designed to The average internal degree of the algorithms set.  \[f(S) = \frac{2m_S}{n_S}\] where \(m_S\) is the number of algorithms internal edges and \(n_S\) is the number of algorithms nodes. .
The NodeClustering.average_internal_degree method returns:
""""""
a FitnessResult object/a list of community-wise score
""""""

The method's path is located at cdlib.NodeClustering.


"
NodeClustering.avg_distance,"To address this issue,
we can leverage NodeClustering.avg_distance method.

The NodeClustering.avg_distance method is useful for Average distance. The average distance of a community is defined average path length across all possible pair of nodes composing it. .
The NodeClustering.avg_distance method returns:
""""""
If summary==True a FitnessResult object, otherwise a list of floats.
""""""

The method's path can be found at cdlib.NodeClustering.


"
NodeClustering.avg_embeddedness,"To tackle this problem,
we can utilize NodeClustering.avg_embeddedness method.

The NodeClustering.avg_embeddedness method is beneficial for Average embeddedness of nodes within the community. The embeddedness of a node n w.r.t. a community C is the ratio of its degree within the community and its overall degree.  \[emb(n,C) = \frac{k_n^C}{k_n}\] The average embeddedness of a community C is:  \[avg_embd(c) = \frac{1}{|C|} \sum_{i \in C} \frac{k_n^C}{k_n}\] .
The NodeClustering.avg_embeddedness method provides:
""""""
If summary==True a FitnessResult object, otherwise a list of floats.
""""""

The path for method is cdlib.NodeClustering.


"
NodeClustering.avg_odf,"To handle the issue at hand,
we can use NodeClustering.avg_odf method.

The NodeClustering.avg_odf method is useful for Average fraction of edges of a node of a algorithms that point outside the algorithms itself.  \[\frac{1}{n_S} \sum_{u \in S} \frac{|\{(u,v)\in E: v \not\in S\}|}{d(u)}\] where \(E\) is the graph edge set, \(v\) is a node in \(S\), \(d(u)\) is the degree of \(u\) and \(n_S\) is the set of algorithms nodes. .
The NodeClustering.avg_odf method produces:
""""""
a FitnessResult object/a list of community-wise score
""""""

The method's path is located at cdlib.NodeClustering.


"
NodeClustering.avg_transitivity,"In solving this issue,
we can utilize NodeClustering.avg_transitivity method.

The NodeClustering.avg_transitivity method helps to Average transitivity. The average transitivity of a community is defined the as the average clustering coefficient of its nodes w.r.t. their connection within the community itself. .
The NodeClustering.avg_transitivity method returns:
""""""
If summary==True a FitnessResult object, otherwise a list of floats.
""""""

The method's location is cdlib.NodeClustering.


"
NodeClustering.conductance,"To approach the given problem,
we can utilize NodeClustering.conductance method.

The NodeClustering.conductance method serves to Fraction of total edge volume that points outside the algorithms.  \[f(S) = \frac{c_S}{2 m_S+c_S}\] where \(c_S\) is the number of algorithms nodes and, \(m_S\) is the number of algorithms edges .
The NodeClustering.conductance method returns:
""""""
a FitnessResult object/a list of community-wise score
""""""

The method's location is cdlib.NodeClustering.


"
NodeClustering.cut_ratio,"In tackling the problem at hand,
we can employ NodeClustering.cut_ratio method.

The NodeClustering.cut_ratio method helps to Fraction of existing edges (out of all possible edges) leaving the algorithms. ..math:: f(S) = frac{c_S}{n_S (n − n_S)} where \(c_S\) is the number of algorithms nodes and, \(n_S\) is the number of edges on the algorithms boundary .
The NodeClustering.cut_ratio method outputs:
""""""
a FitnessResult object/a list of community-wise score
""""""

The method's path can be found at cdlib.NodeClustering.


"
NodeClustering.edges_inside,"To solve this question,
we can leverage NodeClustering.edges_inside method.

The NodeClustering.edges_inside method functions to Number of edges internal to the algorithms. .
The NodeClustering.edges_inside method produces:
""""""
a FitnessResult object/a list of community-wise score
""""""

The method's path is located at cdlib.NodeClustering.


"
NodeClustering.erdos_renyi_modularity,"To solve this issue,
we can use NodeClustering.erdos_renyi_modularity method.

The NodeClustering.erdos_renyi_modularity method helps to Erdos-Renyi modularity is a variation of the Newman-Girvan one. It assumes that vertices in a network are connected randomly with a constant probability \(p\).  \[Q(S) = \frac{1}{m}\sum_{c \in S} (m_S − \frac{mn_S(n_S −1)}{n(n−1)})\] where \(m\) is the number of graph edges, \(m_S\) is the number of algorithms edges, \(l_S\) is the number of edges from nodes in S to nodes outside S. .
The NodeClustering.erdos_renyi_modularity method produces:
""""""
the Erdos-Renyi modularity score
""""""

The method's path can be found at cdlib.NodeClustering.


"
NodeClustering.expansion,"To address the given problem,
we can use NodeClustering.expansion method.

The NodeClustering.expansion method is designed to Number of edges per algorithms node that point outside the cluster.  \[f(S) = \frac{c_S}{n_S}\] where \(n_S\) is the number of edges on the algorithms boundary, \(c_S\) is the number of algorithms nodes. .
The NodeClustering.expansion method provides:
""""""
a FitnessResult object/a list of community-wise score
""""""

The path for method is cdlib.NodeClustering.


"
NodeClustering.f1,"To address this problem,
we can use NodeClustering.f1 method.

The NodeClustering.f1 method is beneficial for Compute the average F1 score of the optimal algorithms matches among the partitions in input. Works on overlapping/non-overlapping complete/partial coverage partitions. .
The NodeClustering.f1 method produces:
""""""
F1 score (harmonic mean of precision and recall)
""""""

The method's path can be found at cdlib.NodeClustering.


"
NodeClustering.flake_odf,"To tackle the problem,
we can use NodeClustering.flake_odf method.

The NodeClustering.flake_odf method is beneficial for Fraction of nodes in S that have fewer edges pointing inside than to the outside of the algorithms.  \[f(S) = \frac{| \{ u:u \in S,| \{(u,v) \in E: v \in S \}| < d(u)/2 \}|}{n_S}\] where \(E\) is the graph edge set, \(v\) is a node in \(S\), \(d(u)\) is the degree of \(u\) and \(n_S\) is the set of algorithms nodes. .
The NodeClustering.flake_odf method provides:
""""""
a FitnessResult object/a list of community-wise score
""""""

The path for method is cdlib.NodeClustering.


"
NodeClustering.fraction_over_median_degree,"In order to solve the problem,
we can apply NodeClustering.fraction_over_median_degree method.

The NodeClustering.fraction_over_median_degree method is designed to Fraction of algorithms nodes of having internal degree higher than the median degree value.  \[f(S) = \frac{|\{u: u \in S,| \{(u,v): v \in S\}| > d_m\}| }{n_S}\] where \(d_m\) is the internal degree median value .
The NodeClustering.fraction_over_median_degree method outputs:
""""""
a FitnessResult object/a list of community-wise score
""""""

The path for method is cdlib.NodeClustering.


"
NodeClustering.get_description,"To handle the given issue,
we can use NodeClustering.get_description method.

The NodeClustering.get_description method helps to Return a description of the clustering, with the name of the method and its numeric parameters. .
The NodeClustering.get_description method produces:
""""""
a string description of the method.\n 
""""""

The method's path can be found at cdlib.NodeClustering.


"
NodeClustering.hub_dominance,"To solve the problem,
we can leverage NodeClustering.hub_dominance method.

The NodeClustering.hub_dominance method is useful for Hub dominance. The hub dominance of a community is defined as the ratio of the degree of its most connected node w.r.t. the theoretically maximal degree within the community. .
The NodeClustering.hub_dominance method provides:
""""""
If summary==True a FitnessResult object, otherwise a list of floats.
""""""

The path for method is cdlib.NodeClustering.


"
NodeClustering.internal_edge_density,"To solve this question,
we can utilize NodeClustering.internal_edge_density method.

The NodeClustering.internal_edge_density method functions to The internal density of the algorithms set.  \[f(S) = \frac{m_S}{n_S(n_S−1)/2}\] where \(m_S\) is the number of algorithms internal edges and \(n_S\) is the number of algorithms nodes. .
The NodeClustering.internal_edge_density method produces:
""""""
a FitnessResult object/a list of community-wise score
""""""

The method's path is located at cdlib.NodeClustering.


"
NodeClustering.link_modularity,"To address this issue,
we can leverage NodeClustering.link_modularity method.

The NodeClustering.link_modularity method is useful for Quality function designed for directed graphs with overlapping communities. .
The NodeClustering.link_modularity method returns:
""""""
the link modularity score
""""""

The method's path can be found at cdlib.NodeClustering.


"
NodeClustering.max_odf,"To solve the given question,
we can leverage NodeClustering.max_odf method.

The NodeClustering.max_odf method is Maximum fraction of edges of a node of a algorithms that point outside the algorithms itself.  \[max_{u \in S} \frac{|\{(u,v)\in E: v \not\in S\}|}{d(u)}\] where \(E\) is the graph edge set, \(v\) is a node in \(S\) and \(d(u)\) is the degree of \(u\) .
The NodeClustering.max_odf method returns:
""""""
a FitnessResult object/a list of community-wise score
""""""

The method's path is cdlib.NodeClustering.


"
NodeClustering.modularity_density,"To tackle this problem,
we can utilize NodeClustering.modularity_density method.

The NodeClustering.modularity_density method is beneficial for The modularity density is one of several propositions that envisioned to palliate the resolution limit issue of modularity based measures. The idea of this metric is to include the information about algorithms size into the expected density of algorithms to avoid the negligence of small and dense communities. For each algorithms \(C\) in partition \(S\), it uses the average modularity degree calculated by \(d(C) = d^{int(C)} − d^{ext(C)}\) where \(d^{int(C)}\) and \(d^{ext(C)}\) are the average internal and external degrees of \(C\) respectively to evaluate the fitness of \(C\) in its network. Finally, the modularity density can be calculated as follows:  \[Q(S) = \sum_{C \in S} \frac{1}{n_C} ( \sum_{i \in C} k^{int}_{iC} - \sum_{i \in C} k^{out}_{iC})\] where \(n_C\) is the number of nodes in C, \(k^{int}_{iC}\) is the degree of node i within \(C\) and \(k^{out}_{iC}\) is the deree of node i outside \(C\). .
The NodeClustering.modularity_density method provides:
""""""
the modularity density score
""""""

The path for method is cdlib.NodeClustering.


"
NodeClustering.modularity_overlap,"In solving this issue,
we can utilize NodeClustering.modularity_overlap method.

The NodeClustering.modularity_overlap method helps to Determines the Overlapping Modularity of a partition C on a graph G. Overlapping Modularity is defined as  \[M_{c_{r}}^{ov} = \sum_{i \in c_{r}} \frac{\sum_{j \in c_{r}, i \neq j}a_{ij} - \sum_{j \not \in c_{r}}a_{ij}}{d_{i} \cdot s_{i}} \cdot \frac{n_{c_{r}}^{e}}{n_{c_{r}} \cdot \binom{n_{c_{r}}}{2}}\] .
The NodeClustering.modularity_overlap method returns:
""""""
FitnessResult object
""""""

The method's location is cdlib.NodeClustering.


"
NodeClustering.newman_girvan_modularity,"To handle the issue,
we can leverage NodeClustering.newman_girvan_modularity method.

The NodeClustering.newman_girvan_modularity method is beneficial for Difference the fraction of intra algorithms edges of a partition with the expected number of such edges if distributed according to a null model. In the standard version of modularity, the null model preserves the expected degree sequence of the graph under consideration. In other words, the modularity compares the real network structure with a corresponding one where nodes are connected without any preference about their neighbors.  \[Q(S) = \frac{1}{m}\sum_{c \in S}(m_S - \frac{(2 m_S + l_S)^2}{4m})\] where \(m\) is the number of graph edges, \(m_S\) is the number of algorithms edges, \(l_S\) is the number of edges from nodes in S to nodes outside S. .
The NodeClustering.newman_girvan_modularity method provides:
""""""
the Newman-Girvan modularity score
""""""

The method's path can be found at cdlib.NodeClustering.


"
NodeClustering.nf1,"In tackling the problem at hand,
we can employ NodeClustering.nf1 method.

The NodeClustering.nf1 method helps to Compute the Normalized F1 score of the optimal algorithms matches among the partitions in input. Works on overlapping/non-overlapping complete/partial coverage partitions. .
The NodeClustering.nf1 method outputs:
""""""
MatchingResult instance
""""""

The method's path can be found at cdlib.NodeClustering.


"
NodeClustering.normalized_cut,"To approach the given problem,
we can utilize NodeClustering.normalized_cut method.

The NodeClustering.normalized_cut method serves to Normalized variant of the Cut-Ratio  \[: f(S) = \frac{c_S}{2m_S+c_S} + \frac{c_S}{2(m−m_S )+c_S}\] where \(m\) is the number of graph edges, \(m_S\) is the number of algorithms internal edges and \(c_S\) is the number of algorithms nodes. .
The NodeClustering.normalized_cut method returns:
""""""
a FitnessResult object/a list of community-wise score
""""""

The method's location is cdlib.NodeClustering.


"
NodeClustering.normalized_mutual_information,"To address the problem at hand,
we can utilize NodeClustering.normalized_mutual_information method.

The NodeClustering.normalized_mutual_information method is designed to Normalized Mutual Information between two clusterings. Normalized Mutual Information (NMI) is an normalization of the Mutual Information (MI) score to scale the results between 0 (no mutual information) and 1 (perfect correlation). In this function, mutual information is normalized by sqrt(H(labels_true) * H(labels_pred)) .
The NodeClustering.normalized_mutual_information method returns:
""""""
normalized mutual information score
""""""

The method's path is located at cdlib.NodeClustering.


"
NodeClustering.omega,"To handle the issue at hand,
we can use NodeClustering.omega method.

The NodeClustering.omega method is useful for Index of resemblance for overlapping, complete coverage, network clusterings. .
The NodeClustering.omega method produces:
""""""
omega index
""""""

The method's path is located at cdlib.NodeClustering.


"
NodeClustering.overlapping_normalized_mutual_information_LFK,"To address this issue,
we can leverage NodeClustering.overlapping_normalized_mutual_information_LFK method.

The NodeClustering.overlapping_normalized_mutual_information_LFK method is useful for Overlapping Normalized Mutual Information between two clusterings. Extension of the Normalized Mutual Information (NMI) score to cope with overlapping partitions. This is the version proposed by Lancichinetti et al. .
The NodeClustering.overlapping_normalized_mutual_information_LFK method returns:
""""""
onmi score
""""""

The method's path can be found at cdlib.NodeClustering.


"
NodeClustering.overlapping_normalized_mutual_information_MGH,"To solve this question,
we can utilize NodeClustering.overlapping_normalized_mutual_information_MGH method.

The NodeClustering.overlapping_normalized_mutual_information_MGH method functions to Overlapping Normalized Mutual Information between two clusterings. Extension of the Normalized Mutual Information (NMI) score to cope with overlapping partitions. This is the version proposed by McDaid et al. using a different normalization than the original LFR one. See ref. for more details. .
The NodeClustering.overlapping_normalized_mutual_information_MGH method produces:
""""""
onmi score\n 
""""""

The method's path is located at cdlib.NodeClustering.


"
NodeClustering.scaled_density,"To resolve this issue,
we can use NodeClustering.scaled_density method.

The NodeClustering.scaled_density method serves to Scaled density. The scaled density of a community is defined as the ratio of the community density w.r.t. the complete graph density. .
The NodeClustering.scaled_density method provides:
""""""
If summary==True a FitnessResult object, otherwise a list of floats.
""""""

The method's path is located at cdlib.NodeClustering.


"
NodeClustering.significance,"To solve the problem,
we can leverage NodeClustering.significance method.

The NodeClustering.significance method is useful for Significance estimates how likely a partition of dense communities appear in a random graph. .
The NodeClustering.significance method provides:
""""""
the significance score
""""""

The path for method is cdlib.NodeClustering.


"
NodeClustering.size,"In order to solve the problem,
we can apply NodeClustering.size method.

The NodeClustering.size method is designed to Size is the number of nodes in the community .
The NodeClustering.size method outputs:
""""""
a FitnessResult object/a list of community-wise score
""""""

The path for method is cdlib.NodeClustering.


"
NodeClustering.surprise,"To solve this problem,
we can utilize NodeClustering.surprise method.

The NodeClustering.surprise method is designed to Surprise is statistical approach proposes a quality metric assuming that edges between vertices emerge randomly according to a hyper-geometric distribution. According to the Surprise metric, the higher the score of a partition, the less likely it is resulted from a random realization, the better the quality of the algorithms structure. .
The NodeClustering.surprise method returns:
""""""
the surprise score
""""""

The method's path is located at cdlib.NodeClustering.


"
NodeClustering.to_json,"To handle the given issue,
we can use NodeClustering.to_json method.

The NodeClustering.to_json method helps to Generate a JSON representation of the algorithms object .
The NodeClustering.to_json method produces:
""""""
a JSON formatted string representing the object
""""""

The method's path can be found at cdlib.NodeClustering.


"
NodeClustering.to_node_community_map,"To address the given problem,
we can use NodeClustering.to_node_community_map method.

The NodeClustering.to_node_community_map method is designed to Generate a <node, list(communities)> representation of the current clustering .
The NodeClustering.to_node_community_map method provides:
""""""
dict of the form <node, list(communities)>
""""""

The path for method is cdlib.NodeClustering.


"
NodeClustering.triangle_participation_ratio,"To tackle the problem,
we can use NodeClustering.triangle_participation_ratio method.

The NodeClustering.triangle_participation_ratio method is beneficial for Fraction of algorithms nodes that belong to a triad.  \[f(S) = \frac{ | \{ u: u \in S,\{(v,w):v, w \in S,(u,v) \in E,(u,w) \in E,(v,w) \in E \} \not = \emptyset \} |}{n_S}\] where \(n_S\) is the set of algorithms nodes. .
The NodeClustering.triangle_participation_ratio method provides:
""""""
a FitnessResult object/a list of community-wise score
""""""

The path for method is cdlib.NodeClustering.


"
NodeClustering.variation_of_information,"To solve the given question,
we can leverage NodeClustering.variation_of_information method.

The NodeClustering.variation_of_information method is Variation of Information among two nodes partitions. $$ H(p)+H(q)-2MI(p, q) $$ where MI is the mutual information, H the partition entropy and p,q are the algorithms sets .
The NodeClustering.variation_of_information method returns:
""""""
VI score
""""""

The method's path is cdlib.NodeClustering.


"
NodeClustering.z_modularity,"To solve this question,
we can leverage NodeClustering.z_modularity method.

The NodeClustering.z_modularity method functions to Z-modularity is another variant of the standard modularity proposed to avoid the resolution limit. The concept of this version is based on an observation that the difference between the fraction of edges inside communities and the expected number of such edges in a null model should not be considered as the only contribution to the final quality of algorithms structure. .
The NodeClustering.z_modularity method produces:
""""""
the z-modularity score
""""""

The method's path is located at cdlib.NodeClustering.


"
dpclus,"To address this issue,
we can leverage dpclus algorithm.

The dpclus algorithm is useful for DPClus projects weights onto an unweighted graph using a common neighbors approach. In DPClus, the weight of an edge (u, v) is deﬁned as the number of common neighbors between u and v. Similarly, the weight of a vertex is its weighted degree – the sum of all edges connected to the vertex- DPClus does not natively generate overlapping clusters but does allow for overlapping cluster nodes to be added in a post-processing step. Supported Graph Types .
The dpclus algorithm accepts these parameters:
""""""
g_original: a networkx/igraph object\n weights: label used for the edge weights. Default, None.\n d_threshold: cluster density threshold, default 0.9\n cp_threshold: cluster property threshold, default 0.5\n overlap: wheter to output overlapping or crisp communities. Default, True.
""""""

The dpclus algorithm returns:
""""""
NodeClustering object\n 
""""""

The algorithm's path can be found at cdlib.algorithms.


"
mod_m,"To address this problem,
we can use mod_m algorithm.

The mod_m algorithm is beneficial for Community Discovery algorithm designed to find local optimal community structures in large networks starting from a given source vertex. Supported Graph Types .
The mod_m algorithm needs the following parameters:
""""""
g_original: a networkx/igraph object\n query_node: Id of the network node whose local community is queried.
""""""

The mod_m algorithm produces:
""""""
NodeClustering object\n 
""""""

The algorithm's path can be found at cdlib.algorithms.


"
overlapping_normalized_mutual_information_MGH,"To solve this issue,
we can use overlapping_normalized_mutual_information_MGH function.

The overlapping_normalized_mutual_information_MGH function helps to Overlapping Normalized Mutual Information between two clusterings. Extension of the Normalized Mutual Information (NMI) score to cope with overlapping partitions. This is the version proposed by McDaid et al. using a different normalization than the original LFR one. See ref. for more details. .
The overlapping_normalized_mutual_information_MGH function takes these parameters:
""""""
first_partition: NodeClustering object\n second_partition: NodeClustering object\n normalization: one of “max” or “LFK”. Default “max” (corresponds to the main method described in the article)
""""""

The overlapping_normalized_mutual_information_MGH function produces:
""""""
MatchingResult object\n 
""""""

The function's path can be found at cdlib.evaluation.


"
ebgc,"In order to solve the problem,
we can apply ebgc algorithm.

The ebgc algorithm is designed to The entropy-based clustering approach finds locally optimal clusters by growing a random seed in a manner that minimizes graph entropy. Supported Graph Types .
The ebgc algorithm takes the following parameters:
""""""
g_original: a networkx/igraph object
""""""

The ebgc algorithm outputs:
""""""
NodeClustering object
""""""

The path for algorithm is cdlib.algorithms.


"
purity,"To tackle this problem,
we can utilize purity function.

The purity function is beneficial for Purity is the product of the frequencies of the most frequent labels carried by the nodes within the communities .
The purity function requires these parameters:
""""""
communities: AttrNodeClustering object
""""""

The purity function provides:
""""""
FitnessResult object
""""""

The path for function is cdlib.evaluation.


"
newman_girvan_modularity,"To approach the given problem,
we can utilize newman_girvan_modularity function.

The newman_girvan_modularity function serves to Difference the fraction of intra community edges of a partition with the expected number of such edges if distributed according to a null model. In the standard version of modularity, the null model preserves the expected degree sequence of the graph under consideration. In other words, the modularity compares the real network structure with a corresponding one where nodes are connected without any preference about their neighbors.  \[Q(S) = \frac{1}{m}\sum_{c \in S}(m_S - \frac{(2 m_S + l_S)^2}{4m})\] where \(m\) is the number of graph edges, \(m_S\) is the number of community edges, \(l_S\) is the number of edges from nodes in S to nodes outside S. .
The newman_girvan_modularity function takes parameters as follows:
""""""
graph: a networkx/igraph object\n communities: NodeClustering object
""""""

The newman_girvan_modularity function returns:
""""""
FitnessResult object\n 
""""""

The function's location is cdlib.evaluation.


"
eigenvector,"To address this problem,
we can use eigenvector algorithm.

The eigenvector algorithm is beneficial for Newman’s leading eigenvector method for detecting community structure based on modularity. This is the proper internal of the recursive, divisive algorithm: each split is done by maximizing the modularity regarding the original network. Supported Graph Types .
The eigenvector algorithm needs the following parameters:
""""""
g_original: a networkx/igraph object
""""""

The eigenvector algorithm produces:
""""""
NodeClustering object
""""""

The algorithm's path can be found at cdlib.algorithms.


"
demon,"To address the problem at hand,
we can utilize demon algorithm.

The demon algorithm is designed to Demon is a node-centric bottom-up overlapping community discovery algorithm. It leverages ego-network structures and overlapping label propagation to identify micro-scale communities that are subsequently merged in mesoscale ones. Supported Graph Types .
The demon algorithm requires these parameters:
""""""
g_original: a networkx/igraph object\n epsilon: merging threshold in [0,1], default 0.25.\n min_com_size: minimum community size, default 3.
""""""

The demon algorithm returns:
""""""
NodeClustering object\n 
""""""

The algorithm's path is located at cdlib.algorithms.


"
plot_community_graph,"To handle the issue,
we can leverage plot_community_graph function.

The plot_community_graph function is beneficial for Plot a algorithms-graph with node color coding for communities. .
The plot_community_graph function takes these parameters:
""""""
graph: NetworkX/igraph graph\n partition: NodeClustering object\n figsize: the figure size; it is a pair of float, default (8, 8)\n node_size: int, default 200\n plot_overlaps: bool, default False. Flag to control if multiple algorithms memberships are plotted.\n plot_labels: bool, default False. Flag to control if node labels are plotted.\n cmap: str or Matplotlib colormap, Colormap(Matplotlib colormap) for mapping intensities of nodes. If set to None, original colormap is used..\n top_k: int, Show the top K influential communities. If set to zero or negative value indicates all.\n min_size: int, Exclude communities below the specified minimum size.
""""""

The function's path can be found at cdlib.viz.


"
paris,"To address this issue,
we can leverage paris algorithm.

The paris algorithm is useful for Paris is a hierarchical graph clustering algorithm inspired by modularity-based clustering techniques. The algorithm is agglomerative and based on a simple distance between clusters induced by the probability of sampling node pairs. Supported Graph Types .
The paris algorithm accepts these parameters:
""""""
g_original: a networkx/igraph object
""""""

The paris algorithm returns:
""""""
NodeClustering object
""""""

The algorithm's path can be found at cdlib.algorithms.


"
kclique,"To solve this problem,
we can utilize kclique algorithm.

The kclique algorithm is designed to Find k-clique communities in graph using the percolation method. A k-clique community is the union of all cliques of size k that can be reached through adjacent (sharing k-1 nodes) k-cliques. Supported Graph Types .
The kclique algorithm requires these parameters:
""""""
g_original: a networkx/igraph object\n k: Size of smallest clique
""""""

The kclique algorithm returns:
""""""
NodeClustering object\n 
""""""

The algorithm's path is located at cdlib.algorithms.


"
endntm,"To handle the issue at hand,
we can use endntm algorithm.

The endntm algorithm is useful for Overlapping community detection algorithm based on an ensemble  approach with a distributed neighbourhood threshold method (EnDNTM). EnDNTM uses pre-partitioned disjoint communities generated by the ensemble mechanism and then analyzes the neighbourhood distribution  of boundary nodes in disjoint communities to detect overlapping communities. Supported Graph Types .
The endntm algorithm accepts parameters:
""""""
g_original: a networkx/igraph object\n clusterings: an iterable of Clustering objects (non overlapping node partitions only)\n epsilon: neighbourhood threshold, default 2.
""""""

The endntm algorithm produces:
""""""
NodeClustering object\n 
""""""

The algorithm's path is located at cdlib.algorithms.


"
multicom,"To tackle the problem,
we can use multicom algorithm.

The multicom algorithm is beneficial for MULTICOM is an algorithm for detecting multiple local communities, possibly overlapping, by expanding the initial seed set. This algorithm uses local scoring metrics to define an embedding of the graph around the seed set. Based on this embedding, it picks new seeds in the neighborhood of the original seed set, and uses these new seeds to recover multiple communities. Supported Graph Types .
The multicom algorithm requires these parameters:
""""""
g_original: a networkx/igraph object\n seed_node: Id of the seed node around which we want to detect communities.
""""""

The multicom algorithm provides:
""""""
EdgeClustering object\n 
""""""

The path for algorithm is cdlib.algorithms.


"
gdmp2,"To solve the problem,
we can leverage gdmp2 algorithm.

The gdmp2 algorithm is useful for Gdmp2 is a method for identifying a set of dense subgraphs of a given sparse graph. It is inspired by an effective technique designed for a similar problem—matrix blocking, from a different discipline (solving linear systems). Supported Graph Types .
The gdmp2 algorithm requires these parameters:
""""""
g_original: a networkx/igraph object\n min_threshold: the minimum density threshold parameter to control the density of the output subgraphs, default 0.75
""""""

The gdmp2 algorithm provides:
""""""
NodeClustering object\n 
""""""

The path for algorithm is cdlib.algorithms.


"
random_search,"To handle the given issue,
we can use random_search function.

The random_search function helps to Returns the optimal partition of the specified graph w.r.t. the selected algorithm and quality score over a randomized sample of the input parameters. .
The random_search function takes these parameters:
""""""
method: community discovery method (from nclib.community)\n graph: networkx/igraph object\n parameters: list of Parameter and BoolParameter objects\n quality_score: a fitness function to evaluate the obtained partition (from nclib.evaluation)\n instances: number of randomly selected parameters configurations\n aggregate: function to select the best fitness value. Possible values: min/max
""""""

The random_search function produces:
""""""
at each call the generator yields a tuple composed by: the optimal configuration for the given algorithm, input paramters and fitness function; the obtained communities; the fitness score\n 
""""""

The function's path can be found at cdlib.ensemble.


"
frc_fgsn,"In solving this issue,
we can utilize frc_fgsn algorithm.

The frc_fgsn algorithm helps to Fuzzy-Rough Community Detection on Fuzzy Granular model of Social Network. FRC-FGSN assigns nodes to communities specifying the probability of each association. The flattened partition ensure that each node is associated to the community that maximize such association probability. FRC-FGSN may generate orphan nodes (i.e., nodes not assigned to any community). Supported Graph Types .
The frc_fgsn algorithm requires the following parameters:
""""""
g_original: networkx/igraph object\n theta: community density coefficient\n eps: coupling coefficient of the community. Ranges in [0, 1], small values ensure that only strongly connected node granules are merged togheter.\n r: radius of the granule (int)
""""""

The frc_fgsn algorithm returns:
""""""
FuzzyNodeClustering object\n 
""""""

The algorithm's location is cdlib.algorithms.


"
triangle_participation_ratio,"To solve this question,
we can leverage triangle_participation_ratio function.

The triangle_participation_ratio function functions to Fraction of community nodes that belong to a triad.  \[f(S) = \frac{ | \{ u: u \in S,\{(v,w):v, w \in S,(u,v) \in E,(u,w) \in E,(v,w) \in E \} \not = \emptyset \} |}{n_S}\] where \(n_S\) is the set of community nodes. .
The triangle_participation_ratio function takes the following parameters:
""""""
graph: a networkx/igraph object\n community: NodeClustering object\n summary: boolean. IfTrueit is returned an aggregated score for the partition is returned, otherwise individual-community ones. DefaultTrue.
""""""

The triangle_participation_ratio function produces:
""""""
If summary==True a FitnessResult object, otherwise a list of floats.\n 
""""""

The function's path is located at cdlib.evaluation.


"
avg_embeddedness,"To solve the given question,
we can leverage avg_embeddedness function.

The avg_embeddedness function is Average embeddedness of nodes within the community. The embeddedness of a node n w.r.t. a community C is the ratio of its degree within the community and its overall degree.  \[emb(n,C) = \frac{k_n^C}{k_n}\] The average embeddedness of a community C is:  \[avg_embd(c) = \frac{1}{|C|} \sum_{i \in C} \frac{k_n^C}{k_n}\] .
The avg_embeddedness function accepts parameters:
""""""
graph: a networkx/igraph object\n communities: NodeClustering object\n summary: boolean. IfTrueit is returned an aggregated score for the partition is returned, otherwise individual-community ones. DefaultTrue.
""""""

The avg_embeddedness function returns:
""""""
If summary==True a FitnessResult object, otherwise a list of floats.\n 
""""""

The function's path is cdlib.evaluation.


"
nx_node_integer_mapping,"To solve this question,
we can utilize nx_node_integer_mapping function.

The nx_node_integer_mapping function functions to Maps node labels from strings to integers. .
The nx_node_integer_mapping function takes the following parameters:
""""""
graph: networkx graph
""""""

The nx_node_integer_mapping function produces:
""""""
if the node labels are string: networkx graph, dictionary <numeric_id, original_node_label>, false otherwise
""""""

The function's path is located at cdlib.utils.


"
sbm_dl,"In tackling the problem at hand,
we can employ sbm_dl algorithm.

The sbm_dl algorithm helps to Efficient Monte Carlo and greedy heuristic for the inference of stochastic block models. Fit a non-overlapping stochastic block model (SBM) by minimizing its description length using an agglomerative heuristic. Supported Graph Types .
The sbm_dl algorithm requires the following parameters:
""""""
g_original: network/igraph object
""""""

The sbm_dl algorithm outputs:
""""""
NodeClustering object
""""""

The algorithm's path can be found at cdlib.algorithms.


"
omega,"To resolve this issue,
we can use omega function.

The omega function serves to Index of resemblance for overlapping, complete coverage, network clusterings. .
The omega function takes the following parameters:
""""""
first_partition: NodeClustering object\n second_partition: NodeClustering object
""""""

The omega function provides:
""""""
MatchingResult object\n 
""""""

The function's path is located at cdlib.evaluation.


"
node_perception,"To address this issue,
we can leverage node_perception algorithm.

The node_perception algorithm is useful for Node perception is based on the idea of joining together small sets of nodes. The algorithm first identifies sub-communities corresponding to each node’s perception of the network around it. To perform this step, it considers each node individually, and partition that node’s neighbors into communities using some existing community detection method. Next, it creates a new network in which every node corresponds to a sub-community, and two nodes are linked if their associated sub-communities overlap by at least some threshold amount. Finally, the algorithm identifies overlapping communities in this new network, and for every such community, merge together the associated sub-communities to identify communities in the original network. Supported Graph Types .
The node_perception algorithm requires these parameters:
""""""
g_original: a networkx/igraph object\n threshold: the tolerance required in order to merge communities\n overlap_threshold: the overlap tolerance\n min_comm_size: minimum community size default 3
""""""

The node_perception algorithm returns:
""""""
NodeClustering object\n 
""""""

The algorithm's path can be found at cdlib.algorithms.


"
spectral,"To solve this issue,
we can use spectral algorithm.

The spectral algorithm helps to SCD implements a Spectral Clustering algorithm for Communities Discovery. It is based on Fielder’s vector (obtained from the eigenvector related to the second eigenvalue of the normalized Laplacian) that are leveraged to extract the communities using Kmeans clustering. SCD a hierarchical graph clustering algorithm inspired by modularity-based clustering techniques. The algorithm is agglomerative and based on a simple distance between clusters induced by the probability of sampling node pairs. Supported Graph Types .
The spectral algorithm takes these parameters:
""""""
g_original: a networkx/igraph object\n kmax: maximum number of desired communities (mandatory). Default 2.\n projection_on_smaller_class: a boolean value that if True then it project a bipartite network in the smallest class of node. (default is True)\n scaler: the function to scale the fielder’s vector to apply KMeans
""""""

The spectral algorithm produces:
""""""
NodeClustering object\n 
""""""

The algorithm's path can be found at cdlib.algorithms.


"
nf1,"To address the given problem,
we can use nf1 function.

The nf1 function is designed to Compute the Normalized F1 score of the optimal algorithms matches among the partitions in input. Works on overlapping/non-overlapping complete/partial coverage partitions. .
The nf1 function takes the following parameters:
""""""
first_partition: NodeClustering object\n second_partition: NodeClustering object
""""""

The nf1 function provides:
""""""
MatchingResult object\n 
""""""

The path for function is cdlib.evaluation.


"
core_expansion,"To address this issue,
we can leverage core_expansion algorithm.

The core_expansion algorithm is useful for Core Expansion automatically detect the core of each possible community in the network. Then, it iteratively expand each core by adding the nodes to form the fnal communities. The expansion process is based on the neighborhood overlap measure. Supported Graph Types .
The core_expansion algorithm accepts these parameters:
""""""
g_original: a networkx/igraph object\n tolerance: numerical tollerance, default 0.0001
""""""

The core_expansion algorithm returns:
""""""
NodeClustering object\n 
""""""

The algorithm's path can be found at cdlib.algorithms.


"
pycombo,"To resolve this issue,
we can use pycombo algorithm.

The pycombo algorithm serves to This is an implementation (for Modularity maximization) of the community detection algorithm called “Combo”. Supported Graph Types .
The pycombo algorithm takes the following parameters:
""""""
g_original: a networkx/igraph object\n weight: Optional, defaults to weight. Graph edges property to use as weights. If None, graph assumed to be unweighted. Ignored if graph is passed as string (path to the file), or such property does not exist.\n max_communities: Optional, defaults to None. Maximum number of communities. If <= 0 or None, assume to be infinite.\n modularity_resolution: float, defaults to 1.0. Modularity resolution parameter.\n num_split_attempts: int, defaults to 0. Number of split attempts. If 0, autoadjust this number automatically.\n start_separate: bool, default False. Indicates if Combo should start from assigning each node into its own separate community. This could help to achieve higher modularity, but it makes execution much slower.\n treat_as_modularity: bool, default False. Indicates if edge weights should be treated as modularity scores. If True, the algorithm solves clique partitioning problem over the given graph, treated as modularity graph (matrix). For example, this allows users to provide their own custom ‘modularity’ matrix. modularity_resolution is ignored in this case.\n random_seed: int, defaults to 42. Random seed to use.
""""""

The pycombo algorithm provides:
""""""
NodeClustering object\n 
""""""

The algorithm's path is located at cdlib.algorithms.


"
ga,"To handle the given issue,
we can use ga algorithm.

The ga algorithm helps to Genetic based approach to discover communities in social networks. GA optimizes a simple but efficacious fitness function able to identify densely connected groups of nodes with sparse connections between groups. Supported Graph Types .
The ga algorithm takes these parameters:
""""""
g_original: a networkx/igraph object\n population: \n generation: \n r: 
""""""

The ga algorithm produces:
""""""
NodeClustering object\n 
""""""

The algorithm's path can be found at cdlib.algorithms.


"
adjusted_mutual_information,"To solve the problem,
we can leverage adjusted_mutual_information function.

The adjusted_mutual_information function is useful for Adjusted Mutual Information between two clusterings. Adjusted Mutual Information (AMI) is an adjustment of the Mutual Information (MI) score to account for chance. It accounts for the fact that the MI is generally higher for two clusterings with a larger number of clusters, regardless of whether there is actually more information shared. For two clusterings \(U\) and \(V\), the AMI is given as: AMI(U, V) = [MI(U, V) - E(MI(U, V))] / [max(H(U), H(V)) - E(MI(U, V))]  This metric is independent of the absolute values of the labels: a permutation of the class or cluster label values won’t change the score value in any way. This metric is furthermore symmetric: switching label_true with label_pred will return the same score value. This can be useful to measure the agreement of two independent label assignments strategies on the same dataset when the real ground truth is not known. Be mindful that this function is an order of magnitude slower than other metrics, such as the Adjusted Rand Index. .
The adjusted_mutual_information function requires these parameters:
""""""
first_partition: NodeClustering object\n second_partition: NodeClustering object
""""""

The adjusted_mutual_information function provides:
""""""
MatchingResult object\n 
""""""

The path for function is cdlib.evaluation.


"
max_odf,"To solve this problem,
we can utilize max_odf function.

The max_odf function is designed to Maximum fraction of edges of a node of a community that point outside the community itself.  \[max_{u \in S} \frac{|\{(u,v)\in E: v \not\in S\}|}{d(u)}\] where \(E\) is the graph edge set, \(v\) is a node in \(S\) and \(d(u)\) is the degree of \(u\) .
The max_odf function requires these parameters:
""""""
graph: a networkx/igraph object\n community: NodeClustering object\n summary: boolean. IfTrueit is returned an aggregated score for the partition is returned, otherwise individual-community ones. DefaultTrue.
""""""

The max_odf function returns:
""""""
If summary==True a FitnessResult object, otherwise a list of floats.\n 
""""""

The function's path is located at cdlib.evaluation.


"
rber_pots,"To tackle this problem,
we can utilize rber_pots algorithm.

The rber_pots algorithm is beneficial for rber_pots is a  model where the quality function to optimize is:  \[Q = \sum_{ij} \left(A_{ij} - \gamma p \right)\delta(\sigma_i, \sigma_j)\] where \(A\) is the adjacency matrix,  \(p = \frac{m}{\binom{n}{2}}\) is the overall density of the graph, \(\sigma_i\) denotes the community of node \(i\), \(\delta(\sigma_i, \sigma_j) = 1\) if  \(\sigma_i = \sigma_j\) and 0 otherwise, and, finally \(\gamma\) is a resolution parameter. Supported Graph Types .
The rber_pots algorithm requires these parameters:
""""""
g_original: a networkx/igraph object\n initial_membership: list of int Initial membership for the partition. IfNonethen defaults to a singleton partition. Deafault None\n weights: list of double, or edge attribute Weights of edges. Can be either an iterable or an edge attribute. Deafault None\n node_sizes: list of int, or vertex attribute Sizes of nodes are necessary to know the size of communities in aggregate graphs. Usually this is set to 1 for all nodes, but in specific cases  this could be changed. Deafault None\n resolution_parameter: double >0 A parameter value controlling the coarseness of the clustering. Higher resolutions lead to more communities, while lower resolutions lead to fewer communities. Deafault 1
""""""

The rber_pots algorithm provides:
""""""
NodeClustering object\n 
""""""

The path for algorithm is cdlib.algorithms.


"
infomap_bipartite,"To approach the given problem,
we can utilize infomap_bipartite algorithm.

The infomap_bipartite algorithm serves to Infomap is based on ideas of information theory. The algorithm uses the probability flow of random walks on a bipartite network as a proxy for information flows in the real system and it decomposes the network into modules by compressing a description of the probability flow. Supported Graph Types .
The infomap_bipartite algorithm takes parameters as follows:
""""""
g_original: a networkx/igraph object\n flags: str flags for Infomap
""""""

The infomap_bipartite algorithm returns:
""""""
BiNodeClustering object\n 
""""""

The algorithm's location is cdlib.algorithms.


"
plot_scoring,"To handle the issue at hand,
we can use plot_scoring function.

The plot_scoring function is useful for Plot the scores obtained by a list of methods on a list of graphs. .
The plot_scoring function accepts parameters:
""""""
graphs: list of graphs on which to make computations\n ref_partitions: list of reference clusterings corresponding to graphs\n graph_names: list of the names of the graphs to display\n methods: list of functions that take a graph as input and return a Clustering as output\n scoring: the scoring function to use, default anmi\n nbRuns: number of runs to do for each method on each graph
""""""

The plot_scoring function produces:
""""""
a seaborn lineplot\n 
""""""

The function's path is located at cdlib.viz.


"
aslpaw,"In order to solve the problem,
we can apply aslpaw algorithm.

The aslpaw algorithm is designed to ASLPAw can be used for disjoint and overlapping community detection and works on weighted/unweighted and directed/undirected networks. ASLPAw is adaptive with virtually no configuration parameters. Supported Graph Types .
The aslpaw algorithm takes the following parameters:
""""""
g_original: a networkx/igraph object
""""""

The aslpaw algorithm outputs:
""""""
NodeClustering object
""""""

The path for algorithm is cdlib.algorithms.


"
lfm,"In tackling the problem at hand,
we can employ lfm algorithm.

The lfm algorithm helps to LFM is based on the local optimization of a fitness function. It finds both overlapping communities and the hierarchical structure. Supported Graph Types .
The lfm algorithm requires the following parameters:
""""""
g_original: a networkx/igraph object\n alpha: parameter to controll the size of the communities:  Large values of alpha yield very small communities, small values instead deliver large modules. If alpha is small enough, all nodes end up in the same cluster, the network itself. In most cases, for alpha < 0.5 there is only one community, for alpha > 2 one recovers the smallest communities. A natural choise is alpha =1.
""""""

The lfm algorithm outputs:
""""""
NodeClustering object\n 
""""""

The algorithm's path can be found at cdlib.algorithms.


"
hub_dominance,"To handle the issue,
we can leverage hub_dominance function.

The hub_dominance function is beneficial for Hub dominance. The hub dominance of a community is defined as the ratio of the degree of its most connected node w.r.t. the theoretically maximal degree within the community. .
The hub_dominance function takes these parameters:
""""""
graph: a networkx/igraph object\n communities: NodeClustering object\n summary: boolean. IfTrueit is returned an aggregated score for the partition is returned, otherwise individual-community ones. DefaultTrue.
""""""

The hub_dominance function provides:
""""""
If summary==True a FitnessResult object, otherwise a list of floats.\n 
""""""

The function's path can be found at cdlib.evaluation.


"
belief,"To address the given problem,
we can use belief algorithm.

The belief algorithm is designed to Belief community seeks the consensus of many high-modularity partitions. It does this with a scalable message-passing algorithm, derived by treating the modularity as a Hamiltonian and applying the cavity method. Supported Graph Types .
The belief algorithm takes the following parameters:
""""""
g_original: a networkx/igraph object\n max_it: \n eps: \n reruns_if_not_conv: \n threshold: \n q_max: 
""""""

The belief algorithm provides:
""""""
NodeClustering object\n 
""""""

The path for algorithm is cdlib.algorithms.


"
overlapping_normalized_mutual_information_LFK,"To address this issue,
we can leverage overlapping_normalized_mutual_information_LFK function.

The overlapping_normalized_mutual_information_LFK function is useful for Overlapping Normalized Mutual Information between two clusterings. Extension of the Normalized Mutual Information (NMI) score to cope with overlapping partitions. This is the version proposed by Lancichinetti et al. (1) .
The overlapping_normalized_mutual_information_LFK function requires these parameters:
""""""
first_partition: NodeClustering object\n second_partition: NodeClustering object
""""""

The overlapping_normalized_mutual_information_LFK function returns:
""""""
MatchingResult object\n 
""""""

The function's path can be found at cdlib.evaluation.


"
avg_transitivity,"In solving this issue,
we can utilize avg_transitivity function.

The avg_transitivity function helps to Average transitivity. The average transitivity of a community is defined the as the average clustering coefficient of its nodes w.r.t. their connection within the community itself. .
The avg_transitivity function requires the following parameters:
""""""
graph: a networkx/igraph object\n communities: NodeClustering object\n summary: boolean. IfTrueit is returned an aggregated score for the partition is returned, otherwise individual-community ones. DefaultTrue.
""""""

The avg_transitivity function returns:
""""""
If summary==True a FitnessResult object, otherwise a list of floats.\n 
""""""

The function's location is cdlib.evaluation.


"
erdos_renyi_modularity,"To solve this question,
we can leverage erdos_renyi_modularity function.

The erdos_renyi_modularity function functions to Erdos-Renyi modularity is a variation of the Newman-Girvan one. It assumes that vertices in a network are connected randomly with a constant probability \(p\).  \[Q(S) = \frac{1}{m}\sum_{c \in S} (m_S − \frac{mn_S(n_S −1)}{n(n−1)})\] where \(m\) is the number of graph edges, \(m_S\) is the number of community edges, \(l_S\) is the number of edges from nodes in S to nodes outside S. .
The erdos_renyi_modularity function takes the following parameters:
""""""
graph: a networkx/igraph object\n communities: NodeClustering object
""""""

The erdos_renyi_modularity function produces:
""""""
FitnessResult object\n 
""""""

The function's path is located at cdlib.evaluation.


"
threshold_clustering,"To address this problem,
we can use threshold_clustering algorithm.

The threshold_clustering algorithm is beneficial for Developed for semantic similarity networks, this algorithm specifically targets weighted and directed graphs. Supported Graph Types .
The threshold_clustering algorithm needs the following parameters:
""""""
g_original: a networkx/igraph object\n threshold_function: callable, optional\n Ties smaller than threshold_function(out_ties) are deleted. Example: np.mean, np.median. Default is np.mean.
""""""

The threshold_clustering algorithm produces:
""""""
NodeClustering object\n 
""""""

The algorithm's path can be found at cdlib.algorithms.


"
size,"To address the problem at hand,
we can utilize size function.

The size function is designed to Size is the number of nodes in the community .
The size function requires these parameters:
""""""
graph: a networkx/igraph object\n communities: NodeClustering object\n summary: boolean. IfTrueit is returned an aggregated score for the partition is returned, otherwise individual-community ones. DefaultTrue.
""""""

The size function returns:
""""""
If summary==True a FitnessResult object, otherwise a list of floats.\n 
""""""

The function's path is located at cdlib.evaluation.


"
eva,"To solve this issue,
we can use eva algorithm.

The eva algorithm helps to The Eva algorithm extends the Louvain approach in order to deal with the attributes of the nodes (aka Louvain Extended to Vertex Attributes). It optimizes - combining them linearly - two quality functions, a structural and a clustering one, namely Newman’s modularity and purity, estimated as the product of the frequencies of the most frequent labels carried by the nodes within the communities. A parameter alpha tunes the importance of the two functions: an high value of alpha favors the clustering criterion instead of the structural one. Supported Graph Types .
The eva algorithm takes these parameters:
""""""
g_original: a networkx/igraph object\n labels: dictionary specifying for each node (key) a dict (value) specifying the name attribute (key) and its value (value)\n weight: str, optional the key in graph to use as weight. Default to ‘weight’\n resolution: double, optional  Will change the size of the communities, default to 1.\n alpha: float, assumed in [0,1], optional Will tune the importance of modularity and purity criteria, default to 0.5
""""""

The eva algorithm produces:
""""""
AttrNodeClustering object\n 
""""""

The algorithm's path can be found at cdlib.algorithms.


"
lemon,"To solve the given question,
we can leverage lemon algorithm.

The lemon algorithm is Lemon is a large scale overlapping community detection method based on local expansion via minimum one norm. The algorithm adopts a local expansion method in order to identify the community members from a few exemplary seed members. The algorithm finds the community by seeking a sparse vector in the span of the local spectra such that the seeds are in its support. LEMON can achieve the highest detection accuracy among state-of-the-art proposals. The running time depends on the size of the community rather than that of the entire graph. Supported Graph Types .
The lemon algorithm accepts parameters:
""""""
g_original: a networkx/igraph object\n seeds: Node list\n min_com_size: the minimum size of a single community in the network, default 20\n max_com_size: the maximum size of a single community in the network, default 50\n expand_step: the step of seed set increasement during expansion process, default 6\n subspace_dim: dimension of the subspace; choosing a large dimension is undesirable because it would increase the computation cost of generating local spectra default 3\n walk_steps: the number of step for the random walk, default 3\n biased: boolean; set if the random walk starting from seed nodes, default False
""""""

The lemon algorithm returns:
""""""
NodeClustering object\n 
""""""

The algorithm's path is cdlib.algorithms.


"
remap_node_communities,"To solve this question,
we can utilize remap_node_communities function.

The remap_node_communities function functions to Apply a map to the obtained communities to retreive the original node labels .
The remap_node_communities function takes the following parameters:
""""""
communities: NodeClustering object\n node_map: dictionary <numeric_id, node_label>
""""""

The remap_node_communities function produces:
""""""
remapped communities\n 
""""""

The function's path is located at cdlib.utils.


"
ricci_community,"To tackle the problem,
we can use ricci_community algorithm.

The ricci_community algorithm is beneficial for Curvature is a geometric property to describe the local shape of an object. If we draw two parallel paths on a surface with positive curvature like a sphere, these two paths move closer to each other while for a negatively curved surface like a saddle, these two paths tend to be apart. Currently there are multiple ways to discretize curvature on graph, in this algorithm, we include two of the most frequently used discrete Ricci curvature: Ollivier-Ricci curvature which is based on optimal transportation theory and Forman-Ricci curvature which is base on CW complexes. Edge Ricci curvature is observed to play an important role in the graph structure. An edge with positive curvature represents an edge within a cluster, while a negatively curved edge tent to be a bridge within clusters. Also, negatively curved edges are highly related to graph connectivity, with negatively curved edges removed from a connected graph, the graph soon become disconnected. Ricci flow is a process to uniformized the edge Ricci curvature of the graph. For a given graph, the Ricci flow gives a “Ricci flow metric” on each edge as edge weights, such that under these edge weights, the Ricci curvature of the graph is mostly equal everywhere. In [Ni3], this “Ricci flow metric” is shown to be able to detect communities. Both Ricci curvature and Ricci flow metric can act as a graph fingerprint for graph classification. The different graph gives different edge Ricci curvature distributions and different Ricci flow metric. Supported Graph Types .
The ricci_community algorithm requires these parameters:
""""""
g_original: a networkx/igraph object\n alpha: The parameter for the probability distribution, range from [0 ~ 1]. It means the share of mass to leave on the original node. Default, 0.5.\n method: Transportation method. [“OTD”, “ATD”, “Sinkhorn”]. Default: Sinkhorn
""""""

The ricci_community algorithm provides:
""""""
NodeClustering object\n 
""""""

The path for algorithm is cdlib.algorithms.


"
angel,"To address the problem at hand,
we can utilize angel algorithm.

The angel algorithm is designed to Angel is a node-centric bottom-up community discovery algorithm. It leverages ego-network structures and overlapping label propagation to identify micro-scale communities that are subsequently merged in mesoscale ones. Angel is the, faster, successor of Demon. Supported Graph Types .
The angel algorithm requires these parameters:
""""""
g_original: a networkx/igraph object\n threshold: merging threshold in [0,1].\n min_community_size: minimum community size, default 3.
""""""

The angel algorithm returns:
""""""
NodeClustering object\n 
""""""

The algorithm's path is located at cdlib.algorithms.


"
percomvc,"To address this issue,
we can leverage percomvc algorithm.

The percomvc algorithm is useful for The PercoMVC approach composes of two steps. In the first step, the algorithm attempts to determine all communities that the clique percolation algorithm may find. In the second step, the algorithm computes the Eigenvector Centrality method on the output of the first step to measure the influence of network nodes and reduce the rate of the unclassified nodes Supported Graph Types .
The percomvc algorithm requires these parameters:
""""""
g_original: a networkx/igraph object
""""""

The percomvc algorithm returns:
""""""
NodeClustering object
""""""

The algorithm's path can be found at cdlib.algorithms.


"
graph_entropy,"In order to solve the problem,
we can apply graph_entropy algorithm.

The graph_entropy algorithm is designed to This method takes advantage of the use of entropy with regard to information theory. Entropy is a measure of uncertainty involved in a random variable. This approach uses a new deﬁnition, Graph Entropy, as a measure of structural complexity in a graph. This algorithm incorporates a seed-growth technique. Unlike the other seed-growth style methods, however, the graph entropy approach does not require any predetermined threshold because it searches for an optimal solution by minimizing graph entropy. This method ﬁnds locally optimal clusters with minimal graph entropy. A seed vertex is selected at random from a candidate set of seed vertices. Then, an initial cluster which is composed of the seed vertex and its immediate neighbors is created. Next, the neighbors are iteratively evaluated for removal to minimize the initial entropy of the graph. Finally, outer boundary vertices are added recursively if their addition causes the entropy of the graph to decrease. Supported Graph Types .
The graph_entropy algorithm takes the following parameters:
""""""
g_original: a networkx/igraph object\n weights: label used for the edge weights.. Default, None
""""""

The graph_entropy algorithm outputs:
""""""
NodeClustering object\n 
""""""

The path for algorithm is cdlib.algorithms.


"
plot_network_clusters,"To address this issue,
we can leverage plot_network_clusters function.

The plot_network_clusters function is useful for Plot a graph with node color coding for communities. .
The plot_network_clusters function accepts these parameters:
""""""
graph: NetworkX/igraph graph\n partition: NodeClustering object\n position: A dictionary with nodes as keys and positions as values. Example: networkx.fruchterman_reingold_layout(G). By default, uses nx.spring_layout(g)\n figsize: the figure size; it is a pair of float, default (8, 8)\n node_size: int, default 200\n plot_overlaps: bool, default False. Flag to control if multiple algorithms memberships are plotted.\n plot_labels: bool, default False. Flag to control if node labels are plotted.\n cmap: str or Matplotlib colormap, Colormap(Matplotlib colormap) for mapping intensities of nodes. If set to None, original colormap is used.\n top_k: int, Show the top K influential communities. If set to zero or negative value indicates all.\n min_size: int, Exclude communities below the specified minimum size.
""""""

The function's path can be found at cdlib.viz.


"
BoolParameter,"To handle the given issue,
we can use BoolParameter function.

The BoolParameter function helps to Initialize self.  See help(type(self)) for accurate signature.
The function's path can be found at cdlib.ensemble.


"
wCommunity,"To approach the given problem,
we can utilize wCommunity algorithm.

The wCommunity algorithm serves to Algorithm to identify overlapping communities in weighted graphs Supported Graph Types .
The wCommunity algorithm takes parameters as follows:
""""""
g_original: a networkx/igraph object\n min_bel_degree: the tolerance, in terms of beloging degree, required in order to add a node in a community\n threshold_bel_degree: the tolerance, in terms of beloging degree, required in order to add a node in a ‘NLU’ community\n weightName: name of the edge attribute containing the weights
""""""

The wCommunity algorithm returns:
""""""
NodeClustering object\n 
""""""

The algorithm's location is cdlib.algorithms.


"
modularity_density,"To solve the problem,
we can leverage modularity_density function.

The modularity_density function is useful for The modularity density is one of several propositions that envisioned to palliate the resolution limit issue of modularity based measures. The idea of this metric is to include the information about community size into the expected density of community to avoid the negligence of small and dense communities. For each community \(C\) in partition \(S\), it uses the average modularity degree calculated by \(d(C) = d^{int(C)} − d^{ext(C)}\) where \(d^{int(C)}\) and \(d^{ext(C)}\) are the average internal and external degrees of \(C\) respectively to evaluate the fitness of \(C\) in its network. Finally, the modularity density can be calculated as follows:  \[Q(S) = \sum_{C \in S} \frac{1}{n_C} ( \sum_{i \in C} 2 * \lambda * k^{int}_{iC} - \sum_{i \in C} 2 * (1 - \lambda) * k^{out}_{iC})\] where \(n_C\) is the number of nodes in C, \(k^{int}_{iC}\) is the degree of node i within \(C\), \(k^{out}_{iC}\) is the deree of node i outside \(C\) and \(\lambda\) is a paramter that allows for tuning the measure resolution (its default value, 0.5, computes the standard modularity density score). .
The modularity_density function requires these parameters:
""""""
graph: a networkx/igraph object\n communities: NodeClustering object\n lmbd: resolution parameter, float in [0,1]. Default 0.5.
""""""

The modularity_density function provides:
""""""
FitnessResult object\n 
""""""

The path for function is cdlib.evaluation.


"
der,"To handle the issue at hand,
we can use der algorithm.

The der algorithm is useful for DER is a Diffusion Entropy Reducer graph clustering algorithm. The algorithm uses random walks to embed the graph in a space of measures, after which a modification of k-means in that space is applied. It creates the walks, creates an initialization, runs the algorithm, and finally extracts the communities. Supported Graph Types .
The der algorithm accepts parameters:
""""""
g_original: an undirected networkx graph object\n walk_len: length of the random walk, default 3\n threshold: threshold for stop criteria; if the likelihood_diff is less than threshold tha algorithm stops, default 0.00001\n iter_bound: maximum number of iteration, default 50
""""""

The der algorithm produces:
""""""
NodeClustering object\n 
""""""

The algorithm's path is located at cdlib.algorithms.


"
Parameter,"To address the given problem,
we can use Parameter function.

The Parameter function is designed to Initialize self.  See help(type(self)) for accurate signature.
The path for function is cdlib.ensemble.


"
head_tail,"To solve this issue,
we can use head_tail algorithm.

The head_tail algorithm helps to Identifying homogeneous communities in complex networks by applying head/tail breaks on edge betweenness given its heavy-tailed distribution. Note: this implementation is suited for small-medium sized graphs, and it may take couple of minutes or longer for a bigger graph. Supported Graph Types .
The head_tail algorithm takes these parameters:
""""""
g_original: a networkx/igraph object\n head_tail_ratio: head/tail division rule. Float in [0,1], dafault 0.4.
""""""

The head_tail algorithm produces:
""""""
NodeClustering object\n 
""""""

The algorithm's path can be found at cdlib.algorithms.


"
lais2,"To resolve this issue,
we can use lais2 algorithm.

The lais2 algorithm serves to LAIS2 is an overlapping community discovery algorithm based on the density function. In the algorithm considers the density of a group is defined as the average density of the communication exchanges between the actors of the group. LAIS2 IS composed of two procedures LA (Link Aggregate Algorithm) and IS2 (Iterative Scan Algorithm). Supported Graph Types .
The lais2 algorithm takes the following parameters:
""""""
g_original: a networkx/igraph object
""""""

The lais2 algorithm provides:
""""""
NodeClustering object
""""""

The algorithm's path is located at cdlib.algorithms.


"
plot_sim_matrix,"To address this problem,
we can use plot_sim_matrix function.

The plot_sim_matrix function is beneficial for Plot a similarity matrix between a list of clusterings, using the provided scoring function. .
The plot_sim_matrix function needs the following parameters:
""""""
clusterings: list of clusterings to compare\n scoring: the scoring function to use
""""""

The plot_sim_matrix function produces:
""""""
a ClusterGrid instance\n 
""""""

The function's path can be found at cdlib.viz.


"
grid_search,"To solve this problem,
we can utilize grid_search function.

The grid_search function is designed to Returns the optimal partition of the specified graph w.r.t. the selected algorithm and quality score. .
The grid_search function requires these parameters:
""""""
method: community discovery method (from nclib.community)\n graph: networkx/igraph object\n parameters: list of Parameter and BoolParameter objects\n quality_score: a fitness function to evaluate the obtained partition (from nclib.evaluation)\n aggregate: function to select the best fitness value. Possible values: min/max
""""""

The grid_search function returns:
""""""
at each call the generator yields a tuple composed by: the optimal configuration for the given algorithm, input paramters and fitness function; the obtained communities; the fitness score\n 
""""""

The function's path is located at cdlib.ensemble.


"
mcode,"To solve this question,
we can utilize mcode algorithm.

The mcode algorithm functions to MCODE is the earliest seed-growth method for predicting protein complexes from PPI networks. MCODE works in two steps: .
The mcode algorithm takes the following parameters:
""""""
g_original: a networkx/igraph object\n weights: label used for the edge weights. Default, None.\n weight_threshold: Threshold for similarity weighs
""""""

The mcode algorithm produces:
""""""
NodeClustering object\n 
""""""

The algorithm's path is located at cdlib.algorithms.


"
variation_of_information,"To tackle this problem,
we can utilize variation_of_information function.

The variation_of_information function is beneficial for Variation of Information among two nodes partitions. $$ H(p)+H(q)-2MI(p, q) $$ where MI is the mutual information, H the partition entropy and p,q are the algorithms sets .
The variation_of_information function requires these parameters:
""""""
first_partition: NodeClustering object\n second_partition: NodeClustering object
""""""

The variation_of_information function provides:
""""""
MatchingResult object\n 
""""""

The path for function is cdlib.evaluation.


"
scan,"To solve the given question,
we can leverage scan algorithm.

The scan algorithm is SCAN (Structural Clustering Algorithm for Networks) is an algorithm which detects clusters, hubs and outliers in networks. It clusters vertices based on a structural similarity measure. The method uses the neighborhood of the vertices as clustering criteria instead of only their direct connections. Vertices are grouped into the clusters by how they share neighbors. Supported Graph Types .
The scan algorithm accepts parameters:
""""""
g_original: a networkx/igraph object\n epsilon: the minimum threshold to assigning cluster membership\n mu: minimum number of neineighbors with a structural similarity that exceeds the threshold epsilon
""""""

The scan algorithm returns:
""""""
NodeClustering object\n 
""""""

The algorithm's path is cdlib.algorithms.


"
umstmo,"To tackle the problem,
we can use umstmo algorithm.

The umstmo algorithm is beneficial for Overlapping community detection based on the union of all maximum spanning trees Supported Graph Types .
The umstmo algorithm requires these parameters:
""""""
g_original: a networkx/igraph object
""""""

The umstmo algorithm provides:
""""""
NodeClustering object
""""""

The path for algorithm is cdlib.algorithms.


"
significance,"In tackling the problem at hand,
we can employ significance function.

The significance function helps to Significance estimates how likely a partition of dense communities appear in a random graph. .
The significance function requires the following parameters:
""""""
graph: a networkx/igraph object\n communities: NodeClustering object
""""""

The significance function outputs:
""""""
FitnessResult object\n 
""""""

The function's path can be found at cdlib.evaluation.


"
plot_com_properties_relation,"To solve this question,
we can leverage plot_com_properties_relation function.

The plot_com_properties_relation function functions to Plot the relation between two properties/fitness function of a clustering .
The plot_com_properties_relation function takes the following parameters:
""""""
com_clusters: clustering(s) to analyze (cluster or cluster list)\n com_fitness_x: first fitness/community property\n com_fitness_y: first fitness/community property\n kwargs: parameters for the seaborn lmplot
""""""

The plot_com_properties_relation function produces:
""""""
a seaborn lmplot\n 
""""""

The function's path is located at cdlib.viz.


"
kcut,"In solving this issue,
we can utilize kcut algorithm.

The kcut algorithm helps to An Efficient Spectral Algorithm for Network Community Discovery. Kcut is designed to provide a unique combination of recursive partitioning and direct k-way methods, able to guarantee the efficiency of a recursive approach, while also having the same accuracy as a direct k-way method. Supported Graph Types .
The kcut algorithm requires the following parameters:
""""""
g_original: a networkx/igraph object\n kmax: maximum value of k, dafault 4.
""""""

The kcut algorithm returns:
""""""
NodeClustering object\n 
""""""

The algorithm's location is cdlib.algorithms.


"
avg_distance,"To handle the issue,
we can leverage avg_distance function.

The avg_distance function is beneficial for Average distance. The average distance of a community is defined average path length across all possible pair of nodes composing it. .
The avg_distance function takes these parameters:
""""""
graph: a networkx/igraph object\n communities: NodeClustering object\n summary: boolean. IfTrueit is returned an aggregated score for the partition is returned, otherwise individual-community ones. DefaultTrue.
""""""

The avg_distance function provides:
""""""
If summary==True a FitnessResult object, otherwise a list of floats.\n 
""""""

The function's path can be found at cdlib.evaluation.


"
ilouvain,"In solving this issue,
we can utilize ilouvain algorithm.

The ilouvain algorithm helps to The I-Louvain algorithm extends the Louvain approach in order to deal only with the scalar attributes of the nodes. It optimizes Newman’s modularity combined with an entropy measure. Supported Graph Types .
The ilouvain algorithm requires the following parameters:
""""""
g_original: a networkx/igraph object\n labels: dictionary specifying for each node (key) a dict (value) specifying the name attribute (key) and its value (value)
""""""

The ilouvain algorithm returns:
""""""
AttrNodeClustering object\n 
""""""

The algorithm's location is cdlib.algorithms.


"
agdl,"To tackle the problem,
we can use agdl algorithm.

The agdl algorithm is beneficial for AGDL is a graph-based agglomerative algorithm, for clustering high-dimensional data. The algorithm uses  the indegree and outdegree to characterize the affinity between two clusters. Supported Graph Types .
The agdl algorithm requires these parameters:
""""""
g_original: a networkx/igraph object\n number_communities: number of communities\n kc: size of the neighbor set for each cluster
""""""

The agdl algorithm provides:
""""""
NodeClustering object\n \n \n \n \n Example:\n \n \n \n \n 
""""""

The path for algorithm is cdlib.algorithms.


"
pool,"To tackle this problem,
we can utilize pool function.

The pool function is beneficial for Execute on a pool of community discovery internal on the input graph. .
The pool function requires these parameters:
""""""
methods: list community discovery methods (from nclib.community)\n graph: networkx/igraph object\n configurations: list of lists (one for each method) of Parameter and BoolParameter objects
""""""

The pool function provides:
""""""
at each call the generator yields a tuple composed by: the actual method, its current configuration and the obtained communities\n 
""""""

The path for function is cdlib.ensemble.


"
rb_pots,"To solve this question,
we can utilize rb_pots algorithm.

The rb_pots algorithm functions to Rb_pots is a model where the quality function to optimize is:  \[Q = \sum_{ij} \left(A_{ij} - \gamma \frac{k_i k_j}{2m} \right)\delta(\sigma_i, \sigma_j)\] where \(A\) is the adjacency matrix, \(k_i\) is the (weighted) degree of node \(i\), \(m\) is the total number of edges (or total edge weight), \(\sigma_i\) denotes the community of node \(i\) and \(\delta(\sigma_i, \sigma_j) = 1\) if \(\sigma_i = \sigma_j\) and 0 otherwise. For directed graphs a slightly different formulation is used, as proposed by Leicht and Newman :  \[Q = \sum_{ij} \left(A_{ij} - \gamma \frac{k_i^\mathrm{out} k_j^\mathrm{in}}{m} \right)\delta(\sigma_i, \sigma_j),\] where \(k_i^\mathrm{out}\) and \(k_i^\mathrm{in}\) refers to respectively the outdegree and indegree of node \(i\) , and \(A_{ij}\) refers to an edge from \(i\) to \(j\). Note that this is the same of Leiden algorithm when setting \(\gamma=1\) and normalising by \(2m\), or \(m\) for directed graphs. Supported Graph Types .
The rb_pots algorithm takes the following parameters:
""""""
g_original: a networkx/igraph object\n initial_membership: list of int Initial membership for the partition. IfNonethen defaults to a singleton partition. Deafault None\n weights: list of double, or edge attribute Weights of edges. Can be either an iterable or an edge attribute. Deafault None\n resolution_parameter: double >0 A parameter value controlling the coarseness of the clustering. Higher resolutions lead to more communities, while lower resolutions lead to fewer communities. Default 1
""""""

The rb_pots algorithm produces:
""""""
NodeClustering object\n 
""""""

The algorithm's path is located at cdlib.algorithms.


"
flake_odf,"In order to solve the problem,
we can apply flake_odf function.

The flake_odf function is designed to Fraction of nodes in S that have fewer edges pointing inside than to the outside of the community.  \[f(S) = \frac{| \{ u:u \in S,| \{(u,v) \in E: v \in S \}| < d(u)/2 \}|}{n_S}\] where \(E\) is the graph edge set, \(v\) is a node in \(S\), \(d(u)\) is the degree of \(u\) and \(n_S\) is the set of community nodes. .
The flake_odf function takes the following parameters:
""""""
graph: a networkx/igraph object\n community: NodeClustering object\n summary: boolean. IfTrueit is returned an aggregated score for the partition is returned, otherwise individual-community ones. DefaultTrue.
""""""

The flake_odf function outputs:
""""""
If summary==True a FitnessResult object, otherwise a list of floats.\n 
""""""

The path for function is cdlib.evaluation.


"
ego_networks,"To address this problem,
we can use ego_networks algorithm.

The ego_networks algorithm is beneficial for Ego-networks returns overlapping communities centered at each nodes within a given radius. Supported Graph Types .
The ego_networks algorithm needs the following parameters:
""""""
g_original: a networkx/igraph object\n level: extrac communities with all neighbors of distance<=level from a node. Deafault 1
""""""

The ego_networks algorithm produces:
""""""
NodeClustering object\n 
""""""

The algorithm's path can be found at cdlib.algorithms.


"
modularity_overlap,"To address this issue,
we can leverage modularity_overlap function.

The modularity_overlap function is useful for Determines the Overlapping Modularity of a partition C on a graph G. Overlapping Modularity is defined as .
The modularity_overlap function accepts these parameters:
""""""
graph: a networkx/igraph object\n communities: NodeClustering object\n weight: label identifying the edge weight parameter name (if present), default None
""""""

The modularity_overlap function returns:
""""""
FitnessResult object\n 
""""""

The function's path can be found at cdlib.evaluation.


"
congo,"To resolve this issue,
we can use congo algorithm.

The congo algorithm serves to CONGO (CONGA Optimized) is an optimization of the CONGA algortithm. The CONGO algorithm is the same as CONGA but using local betweenness. The complete CONGO algorithm is as follows: .
The congo algorithm takes the following parameters:
""""""
g_original: a networkx/igraph object\n number_communities: the number of communities desired\n height: The lengh of the longest shortest paths that CONGO considers, default 2
""""""

The congo algorithm provides:
""""""
NodeClustering object\n 
""""""

The algorithm's path is located at cdlib.algorithms.


"
dcs,"In tackling the problem at hand,
we can employ dcs algorithm.

The dcs algorithm helps to Divide and Conquer Strategy Supported Graph Types .
The dcs algorithm requires the following parameters:
""""""
g_original: a networkx/igraph object
""""""

The dcs algorithm outputs:
""""""
NodeClustering object
""""""

The algorithm's path can be found at cdlib.algorithms.


"
girvan_newman,"To approach the given problem,
we can utilize girvan_newman algorithm.

The girvan_newman algorithm serves to The Girvan–Newman algorithm detects communities by progressively removing edges from the original graph. The algorithm removes the “most valuable” edge, traditionally the edge with the highest betweenness centrality, at each step. As the graph breaks down into pieces, the tightly knit community structure is exposed and the result can be depicted as a dendrogram. Supported Graph Types .
The girvan_newman algorithm takes parameters as follows:
""""""
g_original: a networkx/igraph object\n level: the level where to cut the dendrogram
""""""

The girvan_newman algorithm returns:
""""""
NodeClustering object\n 
""""""

The algorithm's location is cdlib.algorithms.


"
MatchingResult,"To handle the issue at hand,
we can use MatchingResult function.

The MatchingResult function is useful for Initialize self.  See help(type(self)) for accurate signature.
The function's path is located at cdlib.evaluation.


"
expansion,"To solve this issue,
we can use expansion function.

The expansion function helps to Number of edges per community node that point outside the cluster.  \[f(S) = \frac{c_S}{n_S}\] where \(c_S\) is the number of edges on the community boundary, \(n_S\) is the number of community nodes. .
The expansion function takes these parameters:
""""""
graph: a networkx/igraph object\n community: NodeClustering object\n summary: boolean. IfTrueit is returned an aggregated score for the partition is returned, otherwise individual-community ones. DefaultTrue.
""""""

The expansion function produces:
""""""
If summary==True a FitnessResult object, otherwise a list of floats.\n 
""""""

The function's path can be found at cdlib.evaluation.


"
walktrap,"To address the given problem,
we can use walktrap algorithm.

The walktrap algorithm is designed to walktrap is an approach based on random walks. The general idea is that if you perform random walks on the graph, then the walks are more likely to stay within the same community because there are only a few edges that lead outside a given community. Walktrap runs short random walks and uses the results of these random walks to merge separate communities in a bottom-up manner. Supported Graph Types .
The walktrap algorithm takes the following parameters:
""""""
g_original: a networkx/igraph object
""""""

The walktrap algorithm provides:
""""""
NodeClusterint object
""""""

The path for algorithm is cdlib.algorithms.


"
avg_odf,"To solve this problem,
we can utilize avg_odf function.

The avg_odf function is designed to Average fraction of edges of a node of a community that point outside the community itself.  \[\frac{1}{n_S} \sum_{u \in S} \frac{|\{(u,v)\in E: v \not\in S\}|}{d(u)}\] where \(E\) is the graph edge set, \(v\) is a node in \(S\), \(d(u)\) is the degree of \(u\) and \(n_S\) is the set of community nodes. .
The avg_odf function requires these parameters:
""""""
graph: a networkx/igraph object\n community: NodeClustering object\n summary: boolean. IfTrueit is returned an aggregated score for the partition is returned, otherwise individual-community ones. DefaultTrue.
""""""

The avg_odf function returns:
""""""
If summary==True a FitnessResult object, otherwise a list of floats.\n 
""""""

The function's path is located at cdlib.evaluation.


"
pool_grid_filter,"To solve the problem,
we can leverage pool_grid_filter function.

The pool_grid_filter function is useful for Execute a pool of community discovery internal on the input graph. Returns the optimal partition for each algorithm given the specified quality function. .
The pool_grid_filter function requires these parameters:
""""""
methods: list community discovery methods (from nclib.community)\n graph: networkx/igraph object\n configurations: list of lists (one for each method) of Parameter and BoolParameter objects\n quality_score: a fitness function to evaluate the obtained partition (from nclib.evaluation)\n aggregate: function to select the best fitness value. Possible values: min/max
""""""

The pool_grid_filter function provides:
""""""
at each call the generator yields a tuple composed by: the actual method, its optimal configuration; the obtained communities; the fitness score.\n 
""""""

The path for function is cdlib.ensemble.


"
async_fluid,"To address the problem at hand,
we can utilize async_fluid algorithm.

The async_fluid algorithm is designed to Fluid Communities (FluidC) is based on the simple idea of fluids (i.e., communities) interacting in an environment (i.e., a non-complete graph), expanding and contracting. It is propagation-based algorithm and it allows to specify the number of desired communities (k) and it is asynchronous, where each vertex update is computed using the latest partial state of the graph. Supported Graph Types .
The async_fluid algorithm requires these parameters:
""""""
g_original: a networkx/igraph object\n k: Number of communities to search
""""""

The async_fluid algorithm returns:
""""""
EdgeClustering object\n 
""""""

The algorithm's path is located at cdlib.algorithms.


"
em,"To handle the issue,
we can leverage em algorithm.

The em algorithm is beneficial for EM is based on based on a mixture model. The algorithm uses the expectation–maximization algorithm to detect structure in networks. Supported Graph Types .
The em algorithm takes these parameters:
""""""
g_original: a networkx/igraph object\n k: the number of desired communities
""""""

The em algorithm provides:
""""""
NodeClustering object\n 
""""""

The algorithm's path can be found at cdlib.algorithms.


"
scaled_density,"To solve this question,
we can leverage scaled_density function.

The scaled_density function functions to Scaled density. The scaled density of a community is defined as the ratio of the community density w.r.t. the complete graph density. .
The scaled_density function takes the following parameters:
""""""
graph: a networkx/igraph object\n communities: NodeClustering object\n summary: boolean. IfTrueit is returned an aggregated score for the partition is returned, otherwise individual-community ones. DefaultTrue.
""""""

The scaled_density function produces:
""""""
If summary==True a FitnessResult object, otherwise a list of floats.\n 
""""""

The function's path is located at cdlib.evaluation.


"
grid_execution,"To handle the given issue,
we can use grid_execution function.

The grid_execution function helps to Instantiate the specified community discovery method performing a grid search on the parameter set. .
The grid_execution function takes these parameters:
""""""
method: community discovery method (from nclib.community)\n graph: networkx/igraph object\n parameters: list of Parameter and BoolParameter objects
""""""

The grid_execution function produces:
""""""
at each call the generator yields a tuple composed by the current configuration and the obtained communities\n 
""""""

The function's path can be found at cdlib.ensemble.


"
surprise_communities,"To address this issue,
we can leverage surprise_communities algorithm.

The surprise_communities algorithm is useful for Surprise_communities is a model where the quality function to optimize is:  \[Q = m D(q \parallel \langle q \rangle)\] where \(m\) is the number of edges,  \(q = \frac{\sum_c m_c}{m}\),  is the fraction of internal edges, \(\langle q \rangle = \frac{\sum_c \binom{n_c}{2}}{\binom{n}{2}}\) is the expected fraction of internal edges, and finally \(D(x \parallel y) = x \ln \frac{x}{y} + (1 - x) \ln \frac{1 - x}{1 - y}\)  is the binary Kullback-Leibler divergence. For directed graphs we can multiplying the binomials by 2, and this leaves \(\langle q \rangle\) unchanged, so that we can simply use the same formulation.  For weighted graphs we can simply count the total internal weight instead of the total number of edges for \(q\) , while \(\langle q \rangle\) remains unchanged. Supported Graph Types .
The surprise_communities algorithm requires these parameters:
""""""
g_original: a networkx/igraph object\n initial_membership: list of int Initial membership for the partition. IfNonethen defaults to a singleton partition. Deafault None\n weights: list of double, or edge attribute Weights of edges. Can be either an iterable or an edge attribute. Deafault None\n node_sizes: list of int, or vertex attribute Sizes of nodes are necessary to know the size of communities in aggregate graphs. Usually this is set to 1 for all nodes, but in specific cases  this could be changed. Deafault None
""""""

The surprise_communities algorithm returns:
""""""
NodeClustering object\n 
""""""

The algorithm's path can be found at cdlib.algorithms.


"
internal_edge_density,"To solve the given question,
we can leverage internal_edge_density function.

The internal_edge_density function is The internal density of the community set. .
The internal_edge_density function accepts parameters:
""""""
graph: a networkx/igraph object\n community: NodeClustering object\n summary: boolean. IfTrueit is returned an aggregated score for the partition is returned, otherwise individual-community ones. DefaultTrue.
""""""

The internal_edge_density function returns:
""""""
If summary==True a FitnessResult object, otherwise a list of floats.\n 
""""""

The function's path is cdlib.evaluation.


"
spinglass,"To solve this problem,
we can utilize spinglass algorithm.

The spinglass algorithm is designed to Spinglass relies on an analogy between a very popular statistical mechanic model called Potts spin glass, and the community structure. It applies the simulated annealing optimization technique on this model to optimize the modularity. Supported Graph Types .
The spinglass algorithm requires these parameters:
""""""
g_original: a networkx/igraph object\n spins: the number of spins to use. This is the upper limit for the number of communities. It is not a problem to supply a (reasonably) big number here, in which case some spin states will be unpopulated.
""""""

The spinglass algorithm returns:
""""""
NodeClustering object\n 
""""""

The algorithm's path is located at cdlib.algorithms.


"
lpam,"To handle the issue at hand,
we can use lpam algorithm.

The lpam algorithm is useful for Link Partitioning Around Medoids Supported Graph Types .
The lpam algorithm accepts parameters:
""""""
g_original: a networkx/igraph object\n k: number of clusters\n threshold: merging threshold in [0,1], default 0.5\n distance: type of distance: “amp” - amplified commute distance, or “cm” - commute distance, or distance matrix between all edges as np ndarray\n seed: random seed for k-medoid heuristic
""""""

The lpam algorithm produces:
""""""
NodeClustering object\n 
""""""

The algorithm's path is located at cdlib.algorithms.


"
slpa,"To solve the problem,
we can leverage slpa algorithm.

The slpa algorithm is useful for SLPA is an overlapping community discovery that extends tha LPA. SLPA consists of the following three stages: 1) the initialization 2) the evolution 3) the post-processing Supported Graph Types .
The slpa algorithm requires these parameters:
""""""
g_original: a networkx/igraph object\n t: maximum number of iterations, default 20\n r: threshold  ∈ [0, 1]. It is used in the post-processing stage: if the probability of seeing a particular label during the whole process is less than r, this label is deleted from a node’s memory. Default 0.1
""""""

The slpa algorithm provides:
""""""
NodeClustering object\n 
""""""

The path for algorithm is cdlib.algorithms.


"
lpanni,"To tackle the problem,
we can use lpanni algorithm.

The lpanni algorithm is beneficial for LPANNI (Label Propagation Algorithm with Neighbor Node Influence) detects overlapping community structures by adopting fixed label propagation sequence based on the ascending order of node importance and label update strategy based on neighbor node influence and historical label preferred strategy. Supported Graph Types .
The lpanni algorithm requires these parameters:
""""""
g_original: a networkx/igraph object\n threshold: Default 0.0001
""""""

The path for algorithm is cdlib.algorithms.


"
adjusted_rand_index,"To solve this question,
we can leverage adjusted_rand_index function.

The adjusted_rand_index function functions to Rand index adjusted for chance. The Rand Index computes a similarity measure between two clusterings by considering all pairs of samples and counting pairs that are assigned in the same or different clusters in the predicted and true clusterings. The raw RI score is then “adjusted for chance” into the ARI score using the following scheme: ARI = (RI - Expected_RI) / (max(RI) - Expected_RI)  The adjusted Rand index is thus ensured to have a value close to 0.0 for random labeling independently of the number of clusters and samples and exactly 1.0 when the clusterings are identical (up to a permutation). ARI is a symmetric measure: adjusted_rand_index(a, b) == adjusted_rand_index(b, a)  .
The adjusted_rand_index function takes the following parameters:
""""""
first_partition: NodeClustering object\n second_partition: NodeClustering object
""""""

The adjusted_rand_index function produces:
""""""
MatchingResult object\n 
""""""

The function's path is located at cdlib.evaluation.


"
tiles,"In order to solve the problem,
we can apply tiles algorithm.

The tiles algorithm is designed to TILES is designed to incrementally identify and update communities in stream graphs. This implementation assume an explicit edge removal when pairwise interactions cease to exist. Supported Graph Types .
The tiles algorithm takes the following parameters:
""""""
dg: dynetx graph object\n obs: community observation interval (default=1)
""""""

The tiles algorithm outputs:
""""""
TemporalClustering object\n 
""""""

The path for algorithm is cdlib.algorithms.


"
significance_communities,"To address this problem,
we can use significance_communities algorithm.

The significance_communities algorithm is beneficial for Significance_communities is a model where the quality function to optimize is:  \[Q = \sum_c \binom{n_c}{2} D(p_c \parallel p)\] where \(n_c\) is the number of nodes in community \(c\), \(p_c = \frac{m_c}{\binom{n_c}{2}}\), is the density of community \(c\),  \(p = \frac{m}{\binom{n}{2}}\)  is the overall density of the graph, and finally  \(D(x \parallel y) = x \ln \frac{x}{y} + (1 - x) \ln \frac{1 - x}{1 - y}\) is the binary Kullback-Leibler divergence. For directed graphs simply multiply the binomials by 2. The expected Significance in Erdos-Renyi graphs behaves roughly as \(\frac{1}{2} n \ln n\) for both directed and undirected graphs in this formulation.  Warning This method is not suitable for weighted graphs.  Supported Graph Types .
The significance_communities algorithm needs the following parameters:
""""""
g_original: a networkx/igraph object\n initial_membership: list of int Initial membership for the partition. IfNonethen defaults to a singleton partition. Deafault None\n node_sizes: list of int, or vertex attribute Sizes of nodes are necessary to know the size of communities in aggregate graphs. Usually this is set to 1 for all nodes, but in specific cases  this could be changed. Deafault None
""""""

The significance_communities algorithm produces:
""""""
NodeClustering object\n 
""""""

The algorithm's path can be found at cdlib.algorithms.


"
average_internal_degree,"In tackling the problem at hand,
we can employ average_internal_degree function.

The average_internal_degree function helps to The average internal degree of the community set.  \[ \begin{align}\begin{aligned}f(S) = \frac{2m_S}{n_S}\\where :math:`m_S` is the number of community internal edges and :math:`n_S` is the number of community nodes.\end{aligned}\end{align} \] .
The average_internal_degree function requires the following parameters:
""""""
graph: a networkx/igraph object\n community: NodeClustering object\n summary: boolean. IfTrueit is returned an aggregated score for the partition is returned, otherwise individual-community ones. DefaultTrue.
""""""

The average_internal_degree function outputs:
""""""
If summary==True a FitnessResult object, otherwise a list of floats.\n 
""""""

The function's path can be found at cdlib.evaluation.


"
conductance,"To address this issue,
we can leverage conductance function.

The conductance function is useful for Fraction of total edge volume that points outside the community.  \[f(S) = \frac{c_S}{2 m_S+c_S}\] where \(c_S\) is the number of community nodes and, \(m_S\) is the number of community edges .
The conductance function accepts these parameters:
""""""
graph: a networkx/igraph object\n community: NodeClustering object\n summary: boolean. IfTrueit is returned an aggregated score for the partition is returned, otherwise individual-community ones. DefaultTrue.
""""""

The conductance function returns:
""""""
If summary==True a FitnessResult object, otherwise a list of floats.\n 
""""""

The function's path can be found at cdlib.evaluation.


"
sbm_dl_nested,"To handle the issue,
we can leverage sbm_dl_nested algorithm.

The sbm_dl_nested algorithm is beneficial for Efficient Monte Carlo and greedy heuristic for the inference of stochastic block models. (nested) Fit a nested non-overlapping stochastic block model (SBM) by minimizing its description length using an agglomerative heuristic. Return the lowest level found. Currently cdlib do not support hierarchical clustering. Supported Graph Types .
The sbm_dl_nested algorithm takes these parameters:
""""""
g_original: igraph/networkx object
""""""

The sbm_dl_nested algorithm provides:
""""""
NodeClustering object
""""""

The algorithm's path can be found at cdlib.algorithms.


"
bayan,"To solve the given question,
we can leverage bayan algorithm.

The bayan algorithm is The Bayan algorithm is community detection method that is capable of providing a globally optimal solution to the modularity maximization problem. Bayan can also be implemented such that it provides an approximation of the maximum modularity with a guarantee of proximity. This algorithm is theoretically grounded by the Integer Programming (IP) formulation of the modularity maximization problem and relies on an exact branch-and-cut scheme for solving the NP-complete optimization problem to global optimality. The algorithm is integrated as an optional feature in CDlib due to its dependency on the Gurobi solver. For a detailed description on how to satisfy such a dependency please refer to the instructions provided in the official documentation: https://github.com/saref/bayan Supported Graph Types .
The bayan algorithm accepts parameters:
""""""
g_original: a networkx/igraph object\n threshold: Threshold is the minimum optimality gap that Bayan should execute till. In the above example if Bayan finds a solution with modularity within 0.001 of the optimal solution, it will return that solution.\n time_allowed: Time allowed is the maximum time in seconds that Bayan should execute for.\n resolution: Resolution is the resolution parameter of the modularity function.
""""""

The bayan algorithm returns:
""""""
NodeClustering object\n 
""""""

The algorithm's path is cdlib.algorithms.


"
coach,"To handle the given issue,
we can use coach algorithm.

The coach algorithm helps to The motivation behind the core-attachment (CoAch) algorithm  comes from the observation that protein complexes often have a dense core of highly interactive proteins. CoAch works in two steps, ﬁrst discovering highly connected regions (“preliminary cores”) of a network and then expanding these regions by adding strongly associated neighbors. The algorithm operates with three user-speciﬁed parameters: minimum core density (for preliminary cores), maximum core affinity (similarity threshold for distinct preliminary cores), and minimum neighbor closeness (for attaching non-core neighbors to preliminary cores). Supported Graph Types .
The coach algorithm takes these parameters:
""""""
g_original: a networkx/igraph object\n density_threshold: minimum core density. Default, 0.7\n affinity_threshold: maximum core affinity. Default, 0.225\n closeness_threshold: minimum neighbor closeness. Default, 0.5
""""""

The coach algorithm produces:
""""""
NodeClustering object\n 
""""""

The algorithm's path can be found at cdlib.algorithms.


"
markov_clustering,"To address the problem at hand,
we can utilize markov_clustering algorithm.

The markov_clustering algorithm is designed to The Markov clustering algorithm (MCL) is based on simulation of (stochastic) flow in graphs. The MCL algorithm finds cluster structure in graphs by a mathematical bootstrapping procedure. The process deterministically computes (the probabilities of) random walks through the graph, and uses two operators transforming one set of probabilities into another. It does so using the language of stochastic matrices (also called Markov matrices) which capture the mathematical concept of random walks on a graph. The MCL algorithm simulates random walks within a graph by alternation of two operators called expansion and inflation. Supported Graph Types .
The markov_clustering algorithm requires these parameters:
""""""
g_original: a networkx/igraph object\n expansion: The cluster expansion factor\n inflation: The cluster inflation factor\n loop_value: Initialization value for self-loops\n iterations: Maximum number of iterations\n (actual number of iterations will be less if convergence is reached)\n pruning_threshold: Threshold below which matrix elements will be set set to 0\n pruning_frequency: Perform pruning every ‘pruning_frequency’\n iterations.\n convergence_check_frequency: Perform the check for convergence\n every convergence_check_frequency iterations
""""""

The markov_clustering algorithm returns:
""""""
NodeClustering object\n 
""""""

The algorithm's path is located at cdlib.algorithms.


"
read_community_json,"To solve this issue,
we can use read_community_json function.

The read_community_json function helps to Read community list from JSON file. .
The read_community_json function takes these parameters:
""""""
path: input filename\n compress: wheter the file is in a copress format, default False
""""""

The read_community_json function produces:
""""""
a Clustering object\n 
""""""

The function's path can be found at cdlib.readwrite.


"
convert_graph_formats,"To tackle this problem,
we can utilize convert_graph_formats function.

The convert_graph_formats function is beneficial for Converts from/to networkx/igraph .
The convert_graph_formats function requires these parameters:
""""""
graph: original graph object\n desired_format: desired final type. Either nx.Graph or ig.Graph\n directed: boolean, defaultFalse
""""""

The convert_graph_formats function provides:
""""""
the converted graph\n 
""""""

The path for function is cdlib.utils.


"
overlapping_seed_set_expansion,"To address the given problem,
we can use overlapping_seed_set_expansion algorithm.

The overlapping_seed_set_expansion algorithm is designed to OSSE is an overlapping community detection algorithm optimizing the conductance community score The algorithm uses a seed set expansion approach; the key idea is to find good seeds, and then expand these seed sets using the personalized PageRank clustering procedure. Supported Graph Types .
The overlapping_seed_set_expansion algorithm takes the following parameters:
""""""
g_original: a networkx/igraph object\n seeds: Node list\n ninf: Neighbourhood Inflation parameter (boolean)\n expansion: Seed expansion: ppr or vppr\n stopping: Stopping criteria: cond\n nworkers: Number of Workers: default 1\n nruns: Number of runs: default 13\n alpha: alpha value for Personalized PageRank expansion: default 0.99\n maxexpand: Maximum expansion allowed for approximate ppr: default INF\n delta: Minimum distance parameter for near duplicate communities: default 0.2
""""""

The overlapping_seed_set_expansion algorithm provides:
""""""
NodeClustering object\n 
""""""

The path for algorithm is cdlib.algorithms.


"
cpm,"To resolve this issue,
we can use cpm algorithm.

The cpm algorithm serves to CPM is a model where the quality function to optimize is:  \[Q = \sum_{ij} \left(A_{ij} - \gamma \right)\delta(\sigma_i, \sigma_j)\] where \(A\) is the adjacency matrix, \(\sigma_i\) denotes the community of node \(i\), \(\delta(\sigma_i, \sigma_j) = 1\) if  \(\sigma_i = \sigma_j\) and 0 otherwise, and, finally \(\gamma\) is a resolution parameter. The internal density of communities  \[p_c = \frac{m_c}{\binom{n_c}{2}} \geq \gamma\] is higher than \(\gamma\), while the external density \(p_{cd} = \frac{m_{cd}}{n_c n_d} \leq \gamma\)    is lower than \(\gamma\). In other words, choosing a particular \(\gamma\) corresponds to choosing to find communities of a particular density, and as such defines communities. Finally, the definition of a community is in a sense independent of the actual graph, which is not the case for any of the other methods. Supported Graph Types .
The cpm algorithm takes the following parameters:
""""""
g_original: a networkx/igraph object\n initial_membership: list of int Initial membership for the partition. IfNonethen defaults to a singleton partition. Deafault None\n weights: list of double, or edge attribute Weights of edges. Can be either an iterable or an edge attribute. Deafault None\n node_sizes: list of int, or vertex attribute Sizes of nodes are necessary to know the size of communities in aggregate graphs. Usually this is set to 1 for all nodes, but in specific cases  this could be changed. Deafault None\n resolution_parameter: double >0 A parameter value controlling the coarseness of the clustering. Higher resolutions lead to more communities, while lower resolutions lead to fewer communities. Deafault 1
""""""

The cpm algorithm provides:
""""""
NodeClustering object\n 
""""""

The algorithm's path is located at cdlib.algorithms.


"
infomap,"To approach the given problem,
we can utilize infomap algorithm.

The infomap algorithm serves to Infomap is based on ideas of information theory. The algorithm uses the probability flow of random walks on a network as a proxy for information flows in the real system and it decomposes the network into modules by compressing a description of the probability flow. NB: in case the Infomap package is not installed/installable (e.g., on M1 silicon Macs), the implementation used is the one from the igraph library. Supported Graph Types .
The infomap algorithm takes parameters as follows:
""""""
g_original: a networkx/igraph object\n flags: str flags for Infomap
""""""

The infomap algorithm returns:
""""""
NodeClustering object\n 
""""""

The algorithm's location is cdlib.algorithms.


"
plot_com_stat,"In solving this issue,
we can utilize plot_com_stat function.

The plot_com_stat function helps to Plot the distribution of a property among all communities for a clustering, or a list of clusterings (violin-plots) .
The plot_com_stat function requires the following parameters:
""""""
com_clusters: list of clusterings to compare, or a single clustering\n com_fitness: the fitness/community property to use
""""""

The plot_com_stat function returns:
""""""
the violin-plots\n 
""""""

The function's location is cdlib.viz.


"
z_modularity,"To solve this question,
we can utilize z_modularity function.

The z_modularity function functions to Z-modularity is another variant of the standard modularity proposed to avoid the resolution limit. The concept of this version is based on an observation that the difference between the fraction of edges inside communities and the expected number of such edges in a null model should not be considered as the only contribution to the final quality of community structure. .
The z_modularity function takes the following parameters:
""""""
graph: a networkx/igraph object\n communities: NodeClustering object
""""""

The z_modularity function produces:
""""""
FitnessResult object\n 
""""""

The function's path is located at cdlib.evaluation.


"
surprise,"To address this issue,
we can leverage surprise function.

The surprise function is useful for Surprise is statistical approach proposes a quality metric assuming that edges between vertices emerge randomly according to a hyper-geometric distribution. According to the Surprise metric, the higher the score of a partition, the less likely it is resulted from a random realization, the better the quality of the community structure. .
The surprise function requires these parameters:
""""""
graph: a networkx/igraph object\n communities: NodeClustering object
""""""

The surprise function returns:
""""""
FitnessResult object\n 
""""""

The function's path can be found at cdlib.evaluation.


"
edges_inside,"To address the problem at hand,
we can utilize edges_inside function.

The edges_inside function is designed to Number of edges internal to the community. .
The edges_inside function requires these parameters:
""""""
graph: a networkx/igraph object\n community: NodeClustering object\n summary: boolean. IfTrueit is returned an aggregated score for the partition is returned, otherwise individual-community ones. DefaultTrue.
""""""

The edges_inside function returns:
""""""
If summary==True a FitnessResult object, otherwise a list of floats.\n 
""""""

The function's path is located at cdlib.evaluation.


"
normalized_cut,"To solve this question,
we can leverage normalized_cut function.

The normalized_cut function functions to Normalized variant of the Cut-Ratio  \[f(S) = \frac{c_S}{2m_S+c_S} + \frac{c_S}{2(m−m_S )+c_S}\] where \(m\) is the number of graph edges, \(m_S\) is the number of community internal edges and \(c_S\) is the number of community nodes. .
The normalized_cut function takes the following parameters:
""""""
graph: a networkx/igraph object\n community: NodeClustering object\n summary: boolean. IfTrueit is returned an aggregated score for the partition is returned, otherwise individual-community ones. DefaultTrue.
""""""

The normalized_cut function produces:
""""""
If summary==True a FitnessResult object, otherwise a list of floats.\n 
""""""

The function's path is located at cdlib.evaluation.


"
CPM_Bipartite,"To address this problem,
we can use CPM_Bipartite algorithm.

The CPM_Bipartite algorithm is beneficial for CPM_Bipartite is the extension of CPM to bipartite graphs Supported Graph Types .
The CPM_Bipartite algorithm needs the following parameters:
""""""
g_original: a networkx/igraph object\n resolution_parameter_01: Resolution parameter for in between two classes.\n resolution_parameter_0: Resolution parameter for class 0.\n resolution_parameter_1: Resolution parameter for class 1.\n degree_as_node_size: IfTrueuse degree as node size instead of 1, to mimic modularity\n seed: the random seed to be used in CPM method to keep results/partitions replicable
""""""

The CPM_Bipartite algorithm produces:
""""""
BiNodeClustering object\n 
""""""

The algorithm's path can be found at cdlib.algorithms.


"
r_spectral_clustering,"To approach the given problem,
we can utilize r_spectral_clustering algorithm.

The r_spectral_clustering algorithm serves to Spectral clustering partitions the nodes of a graph into groups based upon the eigenvectors of the graph Laplacian. Despite the claims of spectral clustering being “popular”, in applied research using graph data, spectral clustering (without regularization) often returns a partition of the nodes that is uninteresting, typically finding a large cluster that contains most of the data and many smaller clusters, each with only a few nodes. This method allows to compute spectral clustering with/withouth different regualarization functions designed to address such a limitation. Supported Graph Types .
The r_spectral_clustering algorithm takes parameters as follows:
""""""
g_original: a networkx/igraph object\n n_clusters: How many clusters to look at\n method: one among “vanilla”, “regularized”, “regularized_with_kmeans”, “sklearn_spectral_embedding”, “sklearn_kmeans”, “percentile”.\n percentile: percentile of the degree distribution to perform regularization. Value in [0, 100]. Mandatory if method=”percentile” or “regularized”, otherwise None
""""""

The r_spectral_clustering algorithm returns:
""""""
NodeClustering object\n 
""""""

The algorithm's location is cdlib.algorithms.


"
principled_clustering,"To solve this problem,
we can utilize principled_clustering algorithm.

The principled_clustering algorithm is designed to An efficient and principled method for detecting communities in networks Supported Graph Types .
The principled_clustering algorithm requires these parameters:
""""""
g_original: networkx/igraph object\n cluster_count: number of desired communities
""""""

The principled_clustering algorithm returns:
""""""
FuzzyNodeClustering object\n 
""""""

The algorithm's path is located at cdlib.algorithms.


"
read_community_csv,"To address this issue,
we can leverage read_community_csv function.

The read_community_csv function is useful for Read community list from comma separated value (csv) file. .
The read_community_csv function accepts these parameters:
""""""
path: input filename\n delimiter: column delimiter\n nodetype: specify the type of node labels, default str\n compress: wheter the file is compressed or not, default False
""""""

The read_community_csv function returns:
""""""
NodeClustering object\n 
""""""

The function's path can be found at cdlib.readwrite.


"
cut_ratio,"To handle the issue,
we can leverage cut_ratio function.

The cut_ratio function is beneficial for Fraction of existing edges (out of all possible edges) leaving the community.  \[f(S) = \frac{c_S}{n_S (n − n_S)}\] where \(c_S\) is the cut size (number of edges on the community boundary) and \(n_S\) is the number of community nodes .
The cut_ratio function takes these parameters:
""""""
graph: a networkx/igraph object\n community: NodeClustering object\n summary: boolean. IfTrueit is returned an aggregated score for the partition is returned, otherwise individual-community ones. DefaultTrue.
""""""

The cut_ratio function provides:
""""""
If summary==True a FitnessResult object, otherwise a list of floats.\n 
""""""

The function's path can be found at cdlib.evaluation.


"
label_propagation,"To solve this question,
we can utilize label_propagation algorithm.

The label_propagation algorithm functions to The Label Propagation algorithm (LPA) detects communities using network structure alone. The algorithm doesn’t require a pre-defined objective function or prior information about the communities. It works as follows: -Every node is initialized with a unique label (an identifier) -These labels propagate through the network -At every iteration of propagation, each node updates its label to the one that the maximum numbers of its neighbours belongs to. Ties are broken uniformly and randomly. -LPA reaches convergence when each node has the majority label of its neighbours. Supported Graph Types .
The label_propagation algorithm takes the following parameters:
""""""
g_original: a networkx/igraph object
""""""

The label_propagation algorithm produces:
""""""
EdgeClustering object
""""""

The algorithm's path is located at cdlib.algorithms.


"
write_community_json,"To resolve this issue,
we can use write_community_json function.

The write_community_json function serves to Generate a JSON representation of the clustering object .
The write_community_json function takes the following parameters:
""""""
communities: a cdlib clustering object\n path: output filename\n compress: wheter to copress the JSON, default False
""""""

The write_community_json function provides:
""""""
a JSON formatted string representing the object\n 
""""""

The function's path is located at cdlib.readwrite.


"
walkscan,"To handle the issue at hand,
we can use walkscan algorithm.

The walkscan algorithm is useful for Random walk community detection method leveraging PageRank node scoring. Supported Graph Types .
The walkscan algorithm accepts parameters:
""""""
g_original: a networkx/igraph object\n nb_steps: the length of the random walk\n eps: DBSCAN eps\n min_samples: DBSCAN min_samples\n init_vector: dictionary node_id -> initial_probability to initialize the random walk. Default, random selected node with probability set to 1.
""""""

The walkscan algorithm produces:
""""""
NodeClustering object\n 
""""""

The algorithm's path is located at cdlib.algorithms.


"
lswl_plus,"To handle the given issue,
we can use lswl_plus algorithm.

The lswl_plus algorithm helps to LSWL+ is capable of finding a partition with overlapping communities or without them, based on user preferences. This method can also find outliers (peripheral nodes of the graph that are marginally connected to communities) and hubs (nodes that bridge the communities) Supported Graph Types .
The lswl_plus algorithm takes these parameters:
""""""
g_original: a networkx/igraph object\n strength_type: 1 strengths between [-1,+1] or, 2 strengths between [0,1]. Default, 2.\n merge_outliers: If outliers need to merge into communities. Default, True.\n detect_overlap: If overlapping communities need to be detected. Default, False
""""""

The lswl_plus algorithm produces:
""""""
NodeClustering object\n 
""""""

The algorithm's path can be found at cdlib.algorithms.


"
hierarchical_link_community,"To address the given problem,
we can use hierarchical_link_community algorithm.

The hierarchical_link_community algorithm is designed to HLC (hierarchical link clustering) is a method to classify links into topologically related groups. The algorithm uses a similarity between links to build a dendrogram where each leaf is a link from the original network and branches represent link communities. At each level of the link dendrogram is calculated the partition density function, based on link density inside communities, to pick the best level to cut. Supported Graph Types .
The hierarchical_link_community algorithm takes the following parameters:
""""""
g_original: a networkx/igraph object
""""""

The hierarchical_link_community algorithm provides:
""""""
EdgeClustering object
""""""

The path for algorithm is cdlib.algorithms.


"
FitnessResult,"To solve the given question,
we can leverage FitnessResult function.

The FitnessResult function is Initialize self.  See help(type(self)) for accurate signature.
The function's path is cdlib.evaluation.


"
lswl,"To solve the problem,
we can leverage lswl algorithm.

The lswl algorithm is useful for LSWL locally discovers networks’ the communities precisely, deterministically, and quickly. This method works in a one-node-expansion model based on a notion of strong and weak links in a graph. Supported Graph Types .
The lswl algorithm requires these parameters:
""""""
g_original: a networkx/igraph object\n timeout: The maximum time in which LSWL should retrieve the community. Default is 1 second.\n strength_type: 1 strengths between [-1,+1] or, 2 strengths between [0,1]. Default, 2.\n query_node: Id of the network node whose local community is queried.\n online: wehter the computation should happen in memory or not. Default, True.
""""""

The lswl algorithm provides:
""""""
NodeClustering object\n 
""""""

The path for algorithm is cdlib.algorithms.


"
link_modularity,"To solve this issue,
we can use link_modularity function.

The link_modularity function helps to Quality function designed for directed graphs with overlapping communities. .
The link_modularity function takes these parameters:
""""""
graph: a networkx/igraph object\n communities: NodeClustering object
""""""

The link_modularity function produces:
""""""
FitnessResult object\n 
""""""

The function's path can be found at cdlib.evaluation.


"
bimlpa,"In solving this issue,
we can utilize bimlpa algorithm.

The bimlpa algorithm helps to BiMLPA is designed to detect the many-to-many correspondence community in bipartite networks using multi-label propagation algorithm. This method works for the connected graph. If the graph is not connected, the method will be applied to each connected component of the graph and the results will be merged. Supported Graph Types .
The bimlpa algorithm requires the following parameters:
""""""
g_original: a networkx/igraph object (instance of igraph.Graph or nx.Graph).\n theta: Label weights threshold. Default 0.3.\n lambd: The max number of labels. Default 7.
""""""

The bimlpa algorithm returns:
""""""
BiNodeClustering object\n 
""""""

The algorithm's location is cdlib.algorithms.


"
ipca,"In order to solve the problem,
we can apply ipca algorithm.

The ipca algorithm is designed to IPCA was introduced by Li et al. (2008) as a modiﬁed version of DPClus. In contrast to DPClus, this method focuses on the maintaining the diameter of a cluster, deﬁned as the maximum shortest distance between all pairs of vertices, rather than its density. In doing so, the seed growth aspect of IPCA emphasizes structural closeness of a predicted protein complex, as well as structural connectivity. Like DPClus, IPCA computes local vertex and edge weights by counting the number of common neighbors shared between two vertices. However, IPCA calculates these values only once at the beginning of the algorithm, rather than updating them every time a discovered cluster is removed from the graph. This allows overlap to occur naturally between clusters, as cluster nodes are not permanently removed from the graph; however, it can also lead to a large amount of cluster overlap. Supported Graph Types .
The ipca algorithm takes the following parameters:
""""""
g_original: a networkx/igraph object\n weights: label used for the edge weights. Default, None.\n t_in: 
""""""

The ipca algorithm outputs:
""""""
NodeClustering object\n 
""""""

The path for algorithm is cdlib.algorithms.


"
f1,"To address this issue,
we can leverage f1 function.

The f1 function is useful for Compute the average F1 score of the optimal algorithms matches among the partitions in input. Works on overlapping/non-overlapping complete/partial coverage partitions. .
The f1 function requires these parameters:
""""""
first_partition: NodeClustering object\n second_partition: NodeClustering object
""""""

The f1 function returns:
""""""
MatchingResult object\n 
""""""

The function's path can be found at cdlib.evaluation.


"
siblinarity_antichain,"In tackling the problem at hand,
we can employ siblinarity_antichain algorithm.

The siblinarity_antichain algorithm helps to The algorithm extract communities from a DAG that (i) respects its intrinsic order and (ii) are composed of similar nodes. The approach takes inspiration from classic similarity measures of bibliometrics, used to assess how similar two publications are, based on their relative citation patterns. Supported Graph Types .
The siblinarity_antichain algorithm requires the following parameters:
""""""
g_original: a networkx/igraph object representing a DAG (directed acyclic graph)\n forwards_backwards_on: checks successors’ similarity. Boolean, default True\n backwards_forwards_on: checks predecessors’ similarity. Boolean, default True\n Lambda: desired resolution of the partition. Default 1\n with_replacement: If True he similarity of a node to itself is equal to the number of its neighbours based on which the similarity is defined. Boolean, default True.
""""""

The siblinarity_antichain algorithm outputs:
""""""
NodeClustering object\n 
""""""

The algorithm's path can be found at cdlib.algorithms.


"
leiden,"To tackle the problem,
we can use leiden algorithm.

The leiden algorithm is beneficial for The Leiden algorithm is an improvement of the Louvain algorithm. The Leiden algorithm consists of three phases: (1) local moving of nodes, (2) refinement of the partition (3) aggregation of the network based on the refined partition, using the non-refined partition to create an initial partition for the aggregate network. Supported Graph Types .
The leiden algorithm requires these parameters:
""""""
g_original: a networkx/igraph object\n initial_membership: list of int Initial membership for the partition. IfNonethen defaults to a singleton partition. Deafault None\n weights: list of double, or edge attribute Weights of edges. Can be either an iterable or an edge attribute. Deafault None
""""""

The leiden algorithm provides:
""""""
NodeClustering object\n 
""""""

The path for algorithm is cdlib.algorithms.


"
mod_r,"To tackle this problem,
we can utilize mod_r algorithm.

The mod_r algorithm is beneficial for Community Discovery algorithm that infers the hierarchy of communities that enclose a given vertex by exploring the graph one vertex at a time. Supported Graph Types .
The mod_r algorithm requires these parameters:
""""""
g_original: a networkx/igraph object\n query_node: Id of the network node whose local community is queried.
""""""

The mod_r algorithm provides:
""""""
NodeClustering object\n 
""""""

The path for algorithm is cdlib.algorithms.


"
normalized_mutual_information,"To address this issue,
we can leverage normalized_mutual_information function.

The normalized_mutual_information function is useful for Normalized Mutual Information between two clusterings. Normalized Mutual Information (NMI) is an normalization of the Mutual Information (MI) score to scale the results between 0 (no mutual information) and 1 (perfect correlation). In this function, mutual information is normalized by sqrt(H(labels_true) * H(labels_pred)) .
The normalized_mutual_information function accepts these parameters:
""""""
first_partition: NodeClustering object\n second_partition: NodeClustering object
""""""

The normalized_mutual_information function returns:
""""""
MatchingResult object\n 
""""""

The function's path can be found at cdlib.evaluation.


"
condor,"To tackle the problem,
we can use condor algorithm.

The condor algorithm is beneficial for BRIM algorithm for bipartite community structure detection. Works on weighted and unweighted graphs. Supported Graph Types .
The condor algorithm requires these parameters:
""""""
g_original: a networkx/igraph object
""""""

The condor algorithm provides:
""""""
BiNodeClustering object
""""""

The path for algorithm is cdlib.algorithms.


"
louvain,"To resolve this issue,
we can use louvain algorithm.

The louvain algorithm serves to Louvain  maximizes a modularity score for each community. The algorithm optimises the modularity in two elementary phases: (1) local moving of nodes; (2) aggregation of the network. In the local moving phase, individual nodes are moved to the community that yields the largest increase in the quality function. In the aggregation phase, an aggregate network is created based on the partition obtained in the local moving phase. Each community in this partition becomes a node in the aggregate network. The two phases are repeated until the quality function cannot be increased further. Supported Graph Types .
The louvain algorithm takes the following parameters:
""""""
g_original: a networkx/igraph object\n weight: str, optional the key in graph to use as weight. Default to ‘weight’\n resolution: double, optional  Will change the size of the communities, default to 1.\n randomize: int, RandomState instance or None, optional (default=None). If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used bynp.random.
""""""

The louvain algorithm provides:
""""""
NodeClustering object\n 
""""""

The algorithm's path is located at cdlib.algorithms.


"
greedy_modularity,"To solve this question,
we can utilize greedy_modularity algorithm.

The greedy_modularity algorithm functions to The CNM algorithm uses the modularity to find the communities strcutures. At every step of the algorithm two communities that contribute maximum positive value to global modularity are merged. Supported Graph Types .
The greedy_modularity algorithm takes the following parameters:
""""""
g_original: a networkx/igraph object\n weight: list of double, or edge attribute Weights of edges. Can be either an iterable or an edge attribute. Deafault None
""""""

The greedy_modularity algorithm produces:
""""""
NodeClustering object\n 
""""""

The algorithm's path is located at cdlib.algorithms.


"
conga,"To handle the issue,
we can leverage conga algorithm.

The conga algorithm is beneficial for CONGA (Cluster-Overlap Newman Girvan Algorithm) is an algorithm for discovering overlapping communities. It extends the  Girvan and Newman’s algorithm with a specific method of deciding when and how to split vertices. The algorithm is as follows: .
The conga algorithm takes these parameters:
""""""
g_original: a networkx/igraph object\n number_communities: the number of communities desired
""""""

The conga algorithm provides:
""""""
NodeClustering object\n 
""""""

The algorithm's path can be found at cdlib.algorithms.


"
fraction_over_median_degree,"To approach the given problem,
we can utilize fraction_over_median_degree function.

The fraction_over_median_degree function serves to Fraction of community nodes of having internal degree higher than the median degree value.  \[f(S) = \frac{|\{u: u \in S,| \{(u,v): v \in S\}| > d_m\}| }{n_S}\] where \(d_m\) is the internal degree median value .
The fraction_over_median_degree function takes parameters as follows:
""""""
graph: a networkx/igraph object\n community: NodeClustering object\n summary: boolean. IfTrueit is returned an aggregated score for the partition is returned, otherwise individual-community ones. DefaultTrue.
""""""

The fraction_over_median_degree function returns:
""""""
If summary==True a FitnessResult object, otherwise a list of floats.\n 
""""""

The function's location is cdlib.evaluation.


"
write_community_csv,"To solve the problem,
we can leverage write_community_csv function.

The write_community_csv function is useful for Save community structure to comma separated value (csv) file. .
The write_community_csv function requires these parameters:
""""""
communities: a NodeClustering object\n path: output filename\n delimiter: column delimiter\n compress: wheter to copress the csv, default False
""""""

The path for function is cdlib.readwrite.


"
